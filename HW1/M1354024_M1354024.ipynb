{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuchi/anaconda3/envs/torch230/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One /home/yuchi/AI/Dataset/training sample: /home/yuchi/AI/Dataset/training/0_0.jpg\n",
      "One /home/yuchi/AI/Dataset/testing sample: /home/yuchi/AI/Dataset/testing/0001.jpg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n",
    "from torchvision.datasets import DatasetFolder, VisionDataset\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "from torchvision import transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "myseed = 6666\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)\n",
    "\n",
    "train_tfm = transforms.Compose([\n",
    "    # Resize the image into a fixed shape (height = width = 128)\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_tfm = transforms.Compose([\n",
    "    # Resize the image into a fixed shape (height = width = 128)\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class FoodDataset(Dataset):\n",
    "\n",
    "    def __init__(self, path, tfm=test_tfm, files=None):\n",
    "        super(FoodDataset, self).__init__()\n",
    "        self.path = path\n",
    "        self.files = sorted([os.path.join(path, x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n",
    "        if files is not None:\n",
    "            self.files = files\n",
    "        print(f\"One {path} sample:\", self.files[0])\n",
    "        self.transform = tfm\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.files[idx]\n",
    "        try:\n",
    "            im = Image.open(fname)\n",
    "\n",
    "            if im.mode == 'RGBA':\n",
    "                im = im.convert('RGB')\n",
    "\n",
    "            im = self.transform(im)\n",
    "\n",
    "            try:\n",
    "                label = int(os.path.basename(fname).split(\"_\")[0])\n",
    "            except ValueError:\n",
    "                label = -1\n",
    "        except OSError:\n",
    "            print(f\"Skip error image: {fname}\")\n",
    "            return None\n",
    "\n",
    "        return im, label\n",
    "    \n",
    "    # Data loading\n",
    "train_dataset  = FoodDataset(\"/home/yuchi/AI/Dataset/training\", tfm=train_tfm)  # Replace with the training dataset path\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)  # Increase batch size for training\n",
    "\n",
    "test_dataset  = FoodDataset(\"/home/yuchi/AI/Dataset/testing\", tfm=test_tfm)  # Replace with the testing dataset path\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 11])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    # 殘差塊定義\n",
    "    extention = 4 # 每個 Bottleneck block 的擴展倍率\n",
    "    def __init__(self, inplanes, planes, stride, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        # 1x1卷積層，用於減少維度\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        # 3x3卷積層，保持特徵圖的大小（除非有 stride 設定）\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        # 1x1卷積層，用於恢復維度（乘上擴展倍率）\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.extention, kernel_size=1, stride=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.extention)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # 如果下采樣不為 None，則應用下采樣\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x # shortcut 是跳躍連接的原始輸入\n",
    "        # 第一個 1x1 卷積層和 BN 操作\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        # 第二個 3x3 卷積層和 BN 操作\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        # 第三個 1x1 卷積層和 BN 操作\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        # 如果需要，對 shortcut 使用下采樣\n",
    "        if self.downsample is not None:\n",
    "            shortcut = self.downsample(x)\n",
    "        # 殘差加和\n",
    "        out = out + shortcut \n",
    "        out = self.relu(out) # 最後一層 ReLU 激活函數\n",
    "        return out\n",
    "\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, block, layers, num_class):\n",
    "        self.inplane = 64 # 初始輸入通道數\n",
    "        super(ResNet50, self).__init__()\n",
    "\n",
    "        self.block = block\n",
    "        self.layers = layers\n",
    "        # 第一層卷積：7x7大小的卷積核，stride=2，padding=3，處理輸入圖像\n",
    "        self.conv1 = nn.Conv2d(3, self.inplane, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplane)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # 四個 block stage，依次增加通道數\n",
    "        self.stage1 = self.make_layer(self.block, 64, layers[0], stride=1)\n",
    "        self.stage2 = self.make_layer(self.block, 128, layers[1], stride=2)\n",
    "        self.stage3 = self.make_layer(self.block, 256, layers[2], stride=2)\n",
    "        self.stage4 = self.make_layer(self.block, 512, layers[3], stride=2)\n",
    "\n",
    "        # Change the avgpool kernel size based on output size after stage4\n",
    "        # 四個 block stage，依次增加通道數\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Adaptive pooling to output (1, 1) # 自適應池化\n",
    "        self.fc = nn.Linear(512 * block.extention, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 第一層卷積和池化\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        # Block部分 # 四個 stage\n",
    "        out = self.stage1(out)\n",
    "        out = self.stage2(out)\n",
    "        out = self.stage3(out)\n",
    "        out = self.stage4(out)\n",
    "        # 池化和全連接層\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "    # 定義如何堆疊多個 Bottleneck block\n",
    "    def make_layer(self, block, plane, block_num, stride=1):\n",
    "        block_list = []\n",
    "        downsample = None\n",
    "        # 如果需要改變尺寸或通道數，定義下采樣\n",
    "        if (stride != 1 or self.inplane != plane * block.extention):\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplane, plane * block.extention, stride=stride, kernel_size=1, bias=False),\n",
    "                nn.BatchNorm2d(plane * block.extention)\n",
    "            )\n",
    "         # 第一個 block 處理 stride 和 downsample\n",
    "        conv_block = block(self.inplane, plane, stride=stride, downsample=downsample)\n",
    "        block_list.append(conv_block)\n",
    "        self.inplane = plane * block.extention\n",
    "        # 添加剩下的 block，這些 block 沒有下采樣\n",
    "        for i in range(1, block_num):\n",
    "            block_list.append(block(self.inplane, plane, stride=1))\n",
    "\n",
    "        return nn.Sequential(*block_list)\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    resnet = ResNet50(Bottleneck, [3, 4, 6, 3], 11)  # Assuming you want 11 classes\n",
    "    x = torch.randn(64, 3, 128, 128)  # Change to 128x128 input\n",
    "    x = resnet(x)\n",
    "    print(x.shape)  # Should output: torch.Size([64, 11])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuchi/anaconda3/envs/torch230/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/yuchi/anaconda3/envs/torch230/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuchi/anaconda3/envs/torch230/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:1, iter:1] Loss: 2.487 | Acc: 9.375% \n",
      "[epoch:1, iter:2] Loss: 2.406 | Acc: 10.156% \n",
      "[epoch:1, iter:3] Loss: 2.352 | Acc: 16.146% \n",
      "[epoch:1, iter:4] Loss: 2.308 | Acc: 17.578% \n",
      "[epoch:1, iter:5] Loss: 2.247 | Acc: 21.562% \n",
      "[epoch:1, iter:6] Loss: 2.199 | Acc: 23.958% \n",
      "[epoch:1, iter:7] Loss: 2.155 | Acc: 27.232% \n",
      "[epoch:1, iter:8] Loss: 2.091 | Acc: 30.078% \n",
      "[epoch:1, iter:9] Loss: 2.046 | Acc: 31.944% \n",
      "[epoch:1, iter:10] Loss: 2.004 | Acc: 33.750% \n",
      "[epoch:1, iter:11] Loss: 1.972 | Acc: 34.375% \n",
      "[epoch:1, iter:12] Loss: 1.920 | Acc: 37.500% \n",
      "[epoch:1, iter:13] Loss: 1.881 | Acc: 38.822% \n",
      "[epoch:1, iter:14] Loss: 1.848 | Acc: 40.067% \n",
      "[epoch:1, iter:15] Loss: 1.808 | Acc: 41.875% \n",
      "[epoch:1, iter:16] Loss: 1.780 | Acc: 42.676% \n",
      "[epoch:1, iter:17] Loss: 1.753 | Acc: 43.474% \n",
      "[epoch:1, iter:18] Loss: 1.721 | Acc: 44.444% \n",
      "[epoch:1, iter:19] Loss: 1.694 | Acc: 45.641% \n",
      "[epoch:1, iter:20] Loss: 1.666 | Acc: 46.797% \n",
      "[epoch:1, iter:21] Loss: 1.635 | Acc: 47.917% \n",
      "[epoch:1, iter:22] Loss: 1.612 | Acc: 48.580% \n",
      "[epoch:1, iter:23] Loss: 1.580 | Acc: 49.592% \n",
      "[epoch:1, iter:24] Loss: 1.549 | Acc: 50.521% \n",
      "[epoch:1, iter:25] Loss: 1.518 | Acc: 51.688% \n",
      "[epoch:1, iter:26] Loss: 1.489 | Acc: 52.644% \n",
      "[epoch:1, iter:27] Loss: 1.464 | Acc: 53.530% \n",
      "[epoch:1, iter:28] Loss: 1.435 | Acc: 54.632% \n",
      "[epoch:1, iter:29] Loss: 1.413 | Acc: 55.172% \n",
      "[epoch:1, iter:30] Loss: 1.395 | Acc: 55.677% \n",
      "[epoch:1, iter:31] Loss: 1.374 | Acc: 56.351% \n",
      "[epoch:1, iter:32] Loss: 1.363 | Acc: 56.689% \n",
      "[epoch:1, iter:33] Loss: 1.341 | Acc: 57.434% \n",
      "[epoch:1, iter:34] Loss: 1.323 | Acc: 57.996% \n",
      "[epoch:1, iter:35] Loss: 1.304 | Acc: 58.527% \n",
      "[epoch:1, iter:36] Loss: 1.292 | Acc: 58.637% \n",
      "[epoch:1, iter:37] Loss: 1.275 | Acc: 59.248% \n",
      "[epoch:1, iter:38] Loss: 1.257 | Acc: 59.910% \n",
      "[epoch:1, iter:39] Loss: 1.243 | Acc: 60.337% \n",
      "[epoch:1, iter:40] Loss: 1.232 | Acc: 60.508% \n",
      "[epoch:1, iter:41] Loss: 1.224 | Acc: 60.823% \n",
      "[epoch:1, iter:42] Loss: 1.211 | Acc: 61.235% \n",
      "[epoch:1, iter:43] Loss: 1.202 | Acc: 61.555% \n",
      "[epoch:1, iter:44] Loss: 1.190 | Acc: 61.896% \n",
      "[epoch:1, iter:45] Loss: 1.179 | Acc: 62.257% \n",
      "[epoch:1, iter:46] Loss: 1.172 | Acc: 62.500% \n",
      "[epoch:1, iter:47] Loss: 1.160 | Acc: 62.799% \n",
      "[epoch:1, iter:48] Loss: 1.150 | Acc: 63.184% \n",
      "[epoch:1, iter:49] Loss: 1.138 | Acc: 63.648% \n",
      "[epoch:1, iter:50] Loss: 1.131 | Acc: 63.906% \n",
      "[epoch:1, iter:51] Loss: 1.117 | Acc: 64.277% \n",
      "[epoch:1, iter:52] Loss: 1.113 | Acc: 64.333% \n",
      "[epoch:1, iter:53] Loss: 1.103 | Acc: 64.623% \n",
      "[epoch:1, iter:54] Loss: 1.090 | Acc: 64.959% \n",
      "[epoch:1, iter:55] Loss: 1.084 | Acc: 65.057% \n",
      "[epoch:1, iter:56] Loss: 1.078 | Acc: 65.318% \n",
      "[epoch:1, iter:57] Loss: 1.070 | Acc: 65.570% \n",
      "[epoch:1, iter:58] Loss: 1.063 | Acc: 65.841% \n",
      "[epoch:1, iter:59] Loss: 1.058 | Acc: 65.916% \n",
      "[epoch:1, iter:60] Loss: 1.052 | Acc: 66.224% \n",
      "[epoch:1, iter:61] Loss: 1.044 | Acc: 66.496% \n",
      "[epoch:1, iter:62] Loss: 1.039 | Acc: 66.683% \n",
      "[epoch:1, iter:63] Loss: 1.032 | Acc: 66.840% \n",
      "[epoch:1, iter:64] Loss: 1.025 | Acc: 67.041% \n",
      "[epoch:1, iter:65] Loss: 1.018 | Acc: 67.308% \n",
      "[epoch:1, iter:66] Loss: 1.011 | Acc: 67.448% \n",
      "[epoch:1, iter:67] Loss: 1.008 | Acc: 67.584% \n",
      "[epoch:1, iter:68] Loss: 1.005 | Acc: 67.670% \n",
      "[epoch:1, iter:69] Loss: 1.002 | Acc: 67.686% \n",
      "[epoch:1, iter:70] Loss: 1.002 | Acc: 67.768% \n",
      "[epoch:1, iter:71] Loss: 0.998 | Acc: 67.804% \n",
      "[epoch:1, iter:72] Loss: 0.991 | Acc: 67.969% \n",
      "[epoch:1, iter:73] Loss: 0.983 | Acc: 68.236% \n",
      "[epoch:1, iter:74] Loss: 0.979 | Acc: 68.370% \n",
      "[epoch:1, iter:75] Loss: 0.974 | Acc: 68.542% \n",
      "[epoch:1, iter:76] Loss: 0.967 | Acc: 68.750% \n",
      "[epoch:1, iter:77] Loss: 0.961 | Acc: 68.953% \n",
      "[epoch:1, iter:78] Loss: 0.961 | Acc: 68.950% \n",
      "[epoch:1, iter:79] Loss: 0.957 | Acc: 69.086% \n",
      "[epoch:1, iter:80] Loss: 0.952 | Acc: 69.277% \n",
      "[epoch:1, iter:81] Loss: 0.946 | Acc: 69.444% \n",
      "[epoch:1, iter:82] Loss: 0.941 | Acc: 69.607% \n",
      "[epoch:1, iter:83] Loss: 0.937 | Acc: 69.729% \n",
      "[epoch:1, iter:84] Loss: 0.933 | Acc: 69.866% \n",
      "[epoch:1, iter:85] Loss: 0.929 | Acc: 70.000% \n",
      "[epoch:1, iter:86] Loss: 0.926 | Acc: 70.113% \n",
      "[epoch:1, iter:87] Loss: 0.923 | Acc: 70.133% \n",
      "[epoch:1, iter:88] Loss: 0.920 | Acc: 70.259% \n",
      "[epoch:1, iter:89] Loss: 0.916 | Acc: 70.435% \n",
      "[epoch:1, iter:90] Loss: 0.912 | Acc: 70.590% \n",
      "[epoch:1, iter:91] Loss: 0.907 | Acc: 70.759% \n",
      "[epoch:1, iter:92] Loss: 0.905 | Acc: 70.856% \n",
      "[epoch:1, iter:93] Loss: 0.901 | Acc: 70.968% \n",
      "[epoch:1, iter:94] Loss: 0.900 | Acc: 71.061% \n",
      "[epoch:1, iter:95] Loss: 0.897 | Acc: 71.168% \n",
      "[epoch:1, iter:96] Loss: 0.894 | Acc: 71.322% \n",
      "[epoch:1, iter:97] Loss: 0.890 | Acc: 71.392% \n",
      "[epoch:1, iter:98] Loss: 0.886 | Acc: 71.524% \n",
      "[epoch:1, iter:99] Loss: 0.882 | Acc: 71.654% \n",
      "[epoch:1, iter:100] Loss: 0.880 | Acc: 71.703% \n",
      "[epoch:1, iter:101] Loss: 0.878 | Acc: 71.782% \n",
      "[epoch:1, iter:102] Loss: 0.873 | Acc: 71.906% \n",
      "Waiting Val...\n",
      "Val's ac is: 0.000%\n",
      "save epoch 0 model\n",
      "\n",
      "Epoch: 2\n",
      "[epoch:2, iter:103] Loss: 0.176 | Acc: 98.438% \n",
      "[epoch:2, iter:104] Loss: 0.202 | Acc: 96.875% \n",
      "[epoch:2, iter:105] Loss: 0.212 | Acc: 95.312% \n",
      "[epoch:2, iter:106] Loss: 0.223 | Acc: 94.531% \n",
      "[epoch:2, iter:107] Loss: 0.240 | Acc: 93.750% \n",
      "[epoch:2, iter:108] Loss: 0.230 | Acc: 94.010% \n",
      "[epoch:2, iter:109] Loss: 0.224 | Acc: 94.196% \n",
      "[epoch:2, iter:110] Loss: 0.228 | Acc: 93.750% \n",
      "[epoch:2, iter:111] Loss: 0.220 | Acc: 94.271% \n",
      "[epoch:2, iter:112] Loss: 0.222 | Acc: 94.062% \n",
      "[epoch:2, iter:113] Loss: 0.227 | Acc: 93.750% \n",
      "[epoch:2, iter:114] Loss: 0.227 | Acc: 93.880% \n",
      "[epoch:2, iter:115] Loss: 0.229 | Acc: 93.870% \n",
      "[epoch:2, iter:116] Loss: 0.225 | Acc: 93.862% \n",
      "[epoch:2, iter:117] Loss: 0.233 | Acc: 93.229% \n",
      "[epoch:2, iter:118] Loss: 0.231 | Acc: 93.359% \n",
      "[epoch:2, iter:119] Loss: 0.230 | Acc: 93.474% \n",
      "[epoch:2, iter:120] Loss: 0.226 | Acc: 93.576% \n",
      "[epoch:2, iter:121] Loss: 0.224 | Acc: 93.832% \n",
      "[epoch:2, iter:122] Loss: 0.220 | Acc: 93.906% \n",
      "[epoch:2, iter:123] Loss: 0.215 | Acc: 94.122% \n",
      "[epoch:2, iter:124] Loss: 0.217 | Acc: 93.892% \n",
      "[epoch:2, iter:125] Loss: 0.215 | Acc: 93.954% \n",
      "[epoch:2, iter:126] Loss: 0.215 | Acc: 93.945% \n",
      "[epoch:2, iter:127] Loss: 0.215 | Acc: 93.812% \n",
      "[epoch:2, iter:128] Loss: 0.214 | Acc: 93.810% \n",
      "[epoch:2, iter:129] Loss: 0.210 | Acc: 93.981% \n",
      "[epoch:2, iter:130] Loss: 0.208 | Acc: 94.085% \n",
      "[epoch:2, iter:131] Loss: 0.205 | Acc: 94.289% \n",
      "[epoch:2, iter:132] Loss: 0.204 | Acc: 94.323% \n",
      "[epoch:2, iter:133] Loss: 0.203 | Acc: 94.355% \n",
      "[epoch:2, iter:134] Loss: 0.202 | Acc: 94.385% \n",
      "[epoch:2, iter:135] Loss: 0.202 | Acc: 94.366% \n",
      "[epoch:2, iter:136] Loss: 0.202 | Acc: 94.347% \n",
      "[epoch:2, iter:137] Loss: 0.201 | Acc: 94.420% \n",
      "[epoch:2, iter:138] Loss: 0.204 | Acc: 94.358% \n",
      "[epoch:2, iter:139] Loss: 0.204 | Acc: 94.341% \n",
      "[epoch:2, iter:140] Loss: 0.202 | Acc: 94.408% \n",
      "[epoch:2, iter:141] Loss: 0.201 | Acc: 94.431% \n",
      "[epoch:2, iter:142] Loss: 0.202 | Acc: 94.297% \n",
      "[epoch:2, iter:143] Loss: 0.201 | Acc: 94.360% \n",
      "[epoch:2, iter:144] Loss: 0.203 | Acc: 94.234% \n",
      "[epoch:2, iter:145] Loss: 0.204 | Acc: 94.222% \n",
      "[epoch:2, iter:146] Loss: 0.204 | Acc: 94.212% \n",
      "[epoch:2, iter:147] Loss: 0.205 | Acc: 94.167% \n",
      "[epoch:2, iter:148] Loss: 0.207 | Acc: 94.022% \n",
      "[epoch:2, iter:149] Loss: 0.210 | Acc: 93.949% \n",
      "[epoch:2, iter:150] Loss: 0.209 | Acc: 93.978% \n",
      "[epoch:2, iter:151] Loss: 0.208 | Acc: 94.005% \n",
      "[epoch:2, iter:152] Loss: 0.208 | Acc: 94.000% \n",
      "[epoch:2, iter:153] Loss: 0.208 | Acc: 93.964% \n",
      "[epoch:2, iter:154] Loss: 0.205 | Acc: 94.050% \n",
      "[epoch:2, iter:155] Loss: 0.206 | Acc: 94.045% \n",
      "[epoch:2, iter:156] Loss: 0.207 | Acc: 93.953% \n",
      "[epoch:2, iter:157] Loss: 0.210 | Acc: 93.778% \n",
      "[epoch:2, iter:158] Loss: 0.210 | Acc: 93.806% \n",
      "[epoch:2, iter:159] Loss: 0.212 | Acc: 93.668% \n",
      "[epoch:2, iter:160] Loss: 0.213 | Acc: 93.642% \n",
      "[epoch:2, iter:161] Loss: 0.213 | Acc: 93.644% \n",
      "[epoch:2, iter:162] Loss: 0.213 | Acc: 93.646% \n",
      "[epoch:2, iter:163] Loss: 0.211 | Acc: 93.648% \n",
      "[epoch:2, iter:164] Loss: 0.210 | Acc: 93.649% \n",
      "[epoch:2, iter:165] Loss: 0.210 | Acc: 93.651% \n",
      "[epoch:2, iter:166] Loss: 0.214 | Acc: 93.506% \n",
      "[epoch:2, iter:167] Loss: 0.212 | Acc: 93.606% \n",
      "[epoch:2, iter:168] Loss: 0.213 | Acc: 93.537% \n",
      "[epoch:2, iter:169] Loss: 0.213 | Acc: 93.517% \n",
      "[epoch:2, iter:170] Loss: 0.214 | Acc: 93.474% \n",
      "[epoch:2, iter:171] Loss: 0.215 | Acc: 93.433% \n",
      "[epoch:2, iter:172] Loss: 0.214 | Acc: 93.438% \n",
      "[epoch:2, iter:173] Loss: 0.213 | Acc: 93.508% \n",
      "[epoch:2, iter:174] Loss: 0.212 | Acc: 93.533% \n",
      "[epoch:2, iter:175] Loss: 0.212 | Acc: 93.557% \n",
      "[epoch:2, iter:176] Loss: 0.211 | Acc: 93.623% \n",
      "[epoch:2, iter:177] Loss: 0.212 | Acc: 93.604% \n",
      "[epoch:2, iter:178] Loss: 0.214 | Acc: 93.544% \n",
      "[epoch:2, iter:179] Loss: 0.214 | Acc: 93.527% \n",
      "[epoch:2, iter:180] Loss: 0.214 | Acc: 93.530% \n",
      "[epoch:2, iter:181] Loss: 0.216 | Acc: 93.513% \n",
      "[epoch:2, iter:182] Loss: 0.216 | Acc: 93.477% \n",
      "[epoch:2, iter:183] Loss: 0.216 | Acc: 93.461% \n",
      "[epoch:2, iter:184] Loss: 0.216 | Acc: 93.445% \n",
      "[epoch:2, iter:185] Loss: 0.215 | Acc: 93.449% \n",
      "[epoch:2, iter:186] Loss: 0.215 | Acc: 93.434% \n",
      "[epoch:2, iter:187] Loss: 0.214 | Acc: 93.456% \n",
      "[epoch:2, iter:188] Loss: 0.215 | Acc: 93.423% \n",
      "[epoch:2, iter:189] Loss: 0.215 | Acc: 93.445% \n",
      "[epoch:2, iter:190] Loss: 0.215 | Acc: 93.395% \n",
      "[epoch:2, iter:191] Loss: 0.214 | Acc: 93.399% \n",
      "[epoch:2, iter:192] Loss: 0.214 | Acc: 93.368% \n",
      "[epoch:2, iter:193] Loss: 0.216 | Acc: 93.286% \n",
      "[epoch:2, iter:194] Loss: 0.218 | Acc: 93.240% \n",
      "[epoch:2, iter:195] Loss: 0.218 | Acc: 93.196% \n",
      "[epoch:2, iter:196] Loss: 0.217 | Acc: 93.235% \n",
      "[epoch:2, iter:197] Loss: 0.216 | Acc: 93.224% \n",
      "[epoch:2, iter:198] Loss: 0.216 | Acc: 93.213% \n",
      "[epoch:2, iter:199] Loss: 0.220 | Acc: 93.138% \n",
      "[epoch:2, iter:200] Loss: 0.220 | Acc: 93.080% \n",
      "[epoch:2, iter:201] Loss: 0.221 | Acc: 93.071% \n",
      "[epoch:2, iter:202] Loss: 0.220 | Acc: 93.062% \n",
      "[epoch:2, iter:203] Loss: 0.220 | Acc: 93.085% \n",
      "[epoch:2, iter:204] Loss: 0.220 | Acc: 93.069% \n",
      "Waiting Val...\n",
      "Val's ac is: 0.000%\n",
      "save epoch 1 model\n",
      "\n",
      "Epoch: 3\n",
      "[epoch:3, iter:205] Loss: 0.097 | Acc: 98.438% \n",
      "[epoch:3, iter:206] Loss: 0.109 | Acc: 96.875% \n",
      "[epoch:3, iter:207] Loss: 0.097 | Acc: 97.917% \n",
      "[epoch:3, iter:208] Loss: 0.087 | Acc: 98.438% \n",
      "[epoch:3, iter:209] Loss: 0.081 | Acc: 98.438% \n",
      "[epoch:3, iter:210] Loss: 0.090 | Acc: 98.177% \n",
      "[epoch:3, iter:211] Loss: 0.098 | Acc: 98.214% \n",
      "[epoch:3, iter:212] Loss: 0.097 | Acc: 98.242% \n",
      "[epoch:3, iter:213] Loss: 0.094 | Acc: 98.438% \n",
      "[epoch:3, iter:214] Loss: 0.094 | Acc: 98.281% \n",
      "[epoch:3, iter:215] Loss: 0.097 | Acc: 98.153% \n",
      "[epoch:3, iter:216] Loss: 0.092 | Acc: 98.307% \n",
      "[epoch:3, iter:217] Loss: 0.089 | Acc: 98.317% \n",
      "[epoch:3, iter:218] Loss: 0.085 | Acc: 98.438% \n",
      "[epoch:3, iter:219] Loss: 0.087 | Acc: 98.333% \n",
      "[epoch:3, iter:220] Loss: 0.085 | Acc: 98.340% \n",
      "[epoch:3, iter:221] Loss: 0.085 | Acc: 98.254% \n",
      "[epoch:3, iter:222] Loss: 0.085 | Acc: 98.177% \n",
      "[epoch:3, iter:223] Loss: 0.082 | Acc: 98.273% \n",
      "[epoch:3, iter:224] Loss: 0.082 | Acc: 98.281% \n",
      "[epoch:3, iter:225] Loss: 0.080 | Acc: 98.363% \n",
      "[epoch:3, iter:226] Loss: 0.078 | Acc: 98.438% \n",
      "[epoch:3, iter:227] Loss: 0.077 | Acc: 98.438% \n",
      "[epoch:3, iter:228] Loss: 0.075 | Acc: 98.503% \n",
      "[epoch:3, iter:229] Loss: 0.075 | Acc: 98.500% \n",
      "[epoch:3, iter:230] Loss: 0.074 | Acc: 98.558% \n",
      "[epoch:3, iter:231] Loss: 0.073 | Acc: 98.553% \n",
      "[epoch:3, iter:232] Loss: 0.072 | Acc: 98.549% \n",
      "[epoch:3, iter:233] Loss: 0.073 | Acc: 98.438% \n",
      "[epoch:3, iter:234] Loss: 0.075 | Acc: 98.229% \n",
      "[epoch:3, iter:235] Loss: 0.074 | Acc: 98.286% \n",
      "[epoch:3, iter:236] Loss: 0.073 | Acc: 98.340% \n",
      "[epoch:3, iter:237] Loss: 0.073 | Acc: 98.390% \n",
      "[epoch:3, iter:238] Loss: 0.073 | Acc: 98.346% \n",
      "[epoch:3, iter:239] Loss: 0.075 | Acc: 98.348% \n",
      "[epoch:3, iter:240] Loss: 0.074 | Acc: 98.394% \n",
      "[epoch:3, iter:241] Loss: 0.073 | Acc: 98.438% \n",
      "[epoch:3, iter:242] Loss: 0.073 | Acc: 98.396% \n",
      "[epoch:3, iter:243] Loss: 0.073 | Acc: 98.397% \n",
      "[epoch:3, iter:244] Loss: 0.071 | Acc: 98.438% \n",
      "[epoch:3, iter:245] Loss: 0.072 | Acc: 98.361% \n",
      "[epoch:3, iter:246] Loss: 0.071 | Acc: 98.363% \n",
      "[epoch:3, iter:247] Loss: 0.072 | Acc: 98.292% \n",
      "[epoch:3, iter:248] Loss: 0.071 | Acc: 98.260% \n",
      "[epoch:3, iter:249] Loss: 0.071 | Acc: 98.299% \n",
      "[epoch:3, iter:250] Loss: 0.072 | Acc: 98.234% \n",
      "[epoch:3, iter:251] Loss: 0.072 | Acc: 98.205% \n",
      "[epoch:3, iter:252] Loss: 0.072 | Acc: 98.210% \n",
      "[epoch:3, iter:253] Loss: 0.072 | Acc: 98.214% \n",
      "[epoch:3, iter:254] Loss: 0.071 | Acc: 98.250% \n",
      "[epoch:3, iter:255] Loss: 0.072 | Acc: 98.254% \n",
      "[epoch:3, iter:256] Loss: 0.073 | Acc: 98.197% \n",
      "[epoch:3, iter:257] Loss: 0.072 | Acc: 98.172% \n",
      "[epoch:3, iter:258] Loss: 0.072 | Acc: 98.148% \n",
      "[epoch:3, iter:259] Loss: 0.071 | Acc: 98.182% \n",
      "[epoch:3, iter:260] Loss: 0.071 | Acc: 98.158% \n",
      "[epoch:3, iter:261] Loss: 0.071 | Acc: 98.136% \n",
      "[epoch:3, iter:262] Loss: 0.071 | Acc: 98.141% \n",
      "[epoch:3, iter:263] Loss: 0.071 | Acc: 98.146% \n",
      "[epoch:3, iter:264] Loss: 0.072 | Acc: 98.125% \n",
      "[epoch:3, iter:265] Loss: 0.072 | Acc: 98.130% \n",
      "[epoch:3, iter:266] Loss: 0.071 | Acc: 98.135% \n",
      "[epoch:3, iter:267] Loss: 0.071 | Acc: 98.115% \n",
      "[epoch:3, iter:268] Loss: 0.071 | Acc: 98.096% \n",
      "[epoch:3, iter:269] Loss: 0.072 | Acc: 98.125% \n",
      "[epoch:3, iter:270] Loss: 0.071 | Acc: 98.130% \n",
      "[epoch:3, iter:271] Loss: 0.071 | Acc: 98.088% \n",
      "[epoch:3, iter:272] Loss: 0.072 | Acc: 98.070% \n",
      "[epoch:3, iter:273] Loss: 0.071 | Acc: 98.098% \n",
      "[epoch:3, iter:274] Loss: 0.071 | Acc: 98.080% \n",
      "[epoch:3, iter:275] Loss: 0.072 | Acc: 98.085% \n",
      "[epoch:3, iter:276] Loss: 0.071 | Acc: 98.069% \n",
      "[epoch:3, iter:277] Loss: 0.071 | Acc: 98.074% \n",
      "[epoch:3, iter:278] Loss: 0.071 | Acc: 98.100% \n",
      "[epoch:3, iter:279] Loss: 0.071 | Acc: 98.104% \n",
      "[epoch:3, iter:280] Loss: 0.071 | Acc: 98.109% \n",
      "[epoch:3, iter:281] Loss: 0.070 | Acc: 98.113% \n",
      "[epoch:3, iter:282] Loss: 0.070 | Acc: 98.117% \n",
      "[epoch:3, iter:283] Loss: 0.069 | Acc: 98.141% \n",
      "[epoch:3, iter:284] Loss: 0.069 | Acc: 98.164% \n",
      "[epoch:3, iter:285] Loss: 0.069 | Acc: 98.129% \n",
      "[epoch:3, iter:286] Loss: 0.069 | Acc: 98.114% \n",
      "[epoch:3, iter:287] Loss: 0.069 | Acc: 98.099% \n",
      "[epoch:3, iter:288] Loss: 0.070 | Acc: 98.065% \n",
      "[epoch:3, iter:289] Loss: 0.070 | Acc: 98.051% \n",
      "[epoch:3, iter:290] Loss: 0.070 | Acc: 98.074% \n",
      "[epoch:3, iter:291] Loss: 0.069 | Acc: 98.096% \n",
      "[epoch:3, iter:292] Loss: 0.069 | Acc: 98.118% \n",
      "[epoch:3, iter:293] Loss: 0.068 | Acc: 98.139% \n",
      "[epoch:3, iter:294] Loss: 0.068 | Acc: 98.160% \n",
      "[epoch:3, iter:295] Loss: 0.069 | Acc: 98.146% \n",
      "[epoch:3, iter:296] Loss: 0.069 | Acc: 98.149% \n",
      "[epoch:3, iter:297] Loss: 0.068 | Acc: 98.152% \n",
      "[epoch:3, iter:298] Loss: 0.068 | Acc: 98.138% \n",
      "[epoch:3, iter:299] Loss: 0.068 | Acc: 98.141% \n",
      "[epoch:3, iter:300] Loss: 0.068 | Acc: 98.161% \n",
      "[epoch:3, iter:301] Loss: 0.067 | Acc: 98.180% \n",
      "[epoch:3, iter:302] Loss: 0.069 | Acc: 98.151% \n",
      "[epoch:3, iter:303] Loss: 0.068 | Acc: 98.153% \n",
      "[epoch:3, iter:304] Loss: 0.068 | Acc: 98.156% \n",
      "[epoch:3, iter:305] Loss: 0.068 | Acc: 98.159% \n",
      "[epoch:3, iter:306] Loss: 0.070 | Acc: 98.144% \n",
      "Waiting Val...\n",
      "Val's ac is: 0.000%\n",
      "save epoch 2 model\n",
      "\n",
      "Epoch: 4\n",
      "[epoch:4, iter:307] Loss: 0.006 | Acc: 100.000% \n",
      "[epoch:4, iter:308] Loss: 0.030 | Acc: 99.219% \n",
      "[epoch:4, iter:309] Loss: 0.022 | Acc: 99.479% \n",
      "[epoch:4, iter:310] Loss: 0.019 | Acc: 99.609% \n",
      "[epoch:4, iter:311] Loss: 0.024 | Acc: 99.375% \n",
      "[epoch:4, iter:312] Loss: 0.024 | Acc: 99.219% \n",
      "[epoch:4, iter:313] Loss: 0.024 | Acc: 99.330% \n",
      "[epoch:4, iter:314] Loss: 0.029 | Acc: 99.219% \n",
      "[epoch:4, iter:315] Loss: 0.029 | Acc: 99.306% \n",
      "[epoch:4, iter:316] Loss: 0.027 | Acc: 99.375% \n",
      "[epoch:4, iter:317] Loss: 0.026 | Acc: 99.432% \n",
      "[epoch:4, iter:318] Loss: 0.024 | Acc: 99.479% \n",
      "[epoch:4, iter:319] Loss: 0.029 | Acc: 99.279% \n",
      "[epoch:4, iter:320] Loss: 0.034 | Acc: 99.219% \n",
      "[epoch:4, iter:321] Loss: 0.034 | Acc: 99.271% \n",
      "[epoch:4, iter:322] Loss: 0.035 | Acc: 99.219% \n",
      "[epoch:4, iter:323] Loss: 0.034 | Acc: 99.265% \n",
      "[epoch:4, iter:324] Loss: 0.034 | Acc: 99.306% \n",
      "[epoch:4, iter:325] Loss: 0.032 | Acc: 99.342% \n",
      "[epoch:4, iter:326] Loss: 0.033 | Acc: 99.297% \n",
      "[epoch:4, iter:327] Loss: 0.033 | Acc: 99.330% \n",
      "[epoch:4, iter:328] Loss: 0.033 | Acc: 99.361% \n",
      "[epoch:4, iter:329] Loss: 0.035 | Acc: 99.253% \n",
      "[epoch:4, iter:330] Loss: 0.035 | Acc: 99.219% \n",
      "[epoch:4, iter:331] Loss: 0.034 | Acc: 99.250% \n",
      "[epoch:4, iter:332] Loss: 0.034 | Acc: 99.219% \n",
      "[epoch:4, iter:333] Loss: 0.034 | Acc: 99.248% \n",
      "[epoch:4, iter:334] Loss: 0.033 | Acc: 99.275% \n",
      "[epoch:4, iter:335] Loss: 0.035 | Acc: 99.138% \n",
      "[epoch:4, iter:336] Loss: 0.035 | Acc: 99.167% \n",
      "[epoch:4, iter:337] Loss: 0.034 | Acc: 99.194% \n",
      "[epoch:4, iter:338] Loss: 0.035 | Acc: 99.121% \n",
      "[epoch:4, iter:339] Loss: 0.035 | Acc: 99.148% \n",
      "[epoch:4, iter:340] Loss: 0.034 | Acc: 99.127% \n",
      "[epoch:4, iter:341] Loss: 0.034 | Acc: 99.152% \n",
      "[epoch:4, iter:342] Loss: 0.034 | Acc: 99.132% \n",
      "[epoch:4, iter:343] Loss: 0.034 | Acc: 99.155% \n",
      "[epoch:4, iter:344] Loss: 0.034 | Acc: 99.178% \n",
      "[epoch:4, iter:345] Loss: 0.034 | Acc: 99.079% \n",
      "[epoch:4, iter:346] Loss: 0.035 | Acc: 99.062% \n",
      "[epoch:4, iter:347] Loss: 0.035 | Acc: 99.085% \n",
      "[epoch:4, iter:348] Loss: 0.034 | Acc: 99.107% \n",
      "[epoch:4, iter:349] Loss: 0.034 | Acc: 99.128% \n",
      "[epoch:4, iter:350] Loss: 0.034 | Acc: 99.148% \n",
      "[epoch:4, iter:351] Loss: 0.033 | Acc: 99.167% \n",
      "[epoch:4, iter:352] Loss: 0.032 | Acc: 99.185% \n",
      "[epoch:4, iter:353] Loss: 0.032 | Acc: 99.202% \n",
      "[epoch:4, iter:354] Loss: 0.032 | Acc: 99.219% \n",
      "[epoch:4, iter:355] Loss: 0.032 | Acc: 99.235% \n",
      "[epoch:4, iter:356] Loss: 0.031 | Acc: 99.250% \n",
      "[epoch:4, iter:357] Loss: 0.033 | Acc: 99.173% \n",
      "[epoch:4, iter:358] Loss: 0.033 | Acc: 99.159% \n",
      "[epoch:4, iter:359] Loss: 0.032 | Acc: 99.175% \n",
      "[epoch:4, iter:360] Loss: 0.033 | Acc: 99.132% \n",
      "[epoch:4, iter:361] Loss: 0.033 | Acc: 99.148% \n",
      "[epoch:4, iter:362] Loss: 0.033 | Acc: 99.135% \n",
      "[epoch:4, iter:363] Loss: 0.033 | Acc: 99.150% \n",
      "[epoch:4, iter:364] Loss: 0.033 | Acc: 99.165% \n",
      "[epoch:4, iter:365] Loss: 0.032 | Acc: 99.179% \n",
      "[epoch:4, iter:366] Loss: 0.032 | Acc: 99.193% \n",
      "[epoch:4, iter:367] Loss: 0.033 | Acc: 99.155% \n",
      "[epoch:4, iter:368] Loss: 0.032 | Acc: 99.168% \n",
      "[epoch:4, iter:369] Loss: 0.032 | Acc: 99.182% \n",
      "[epoch:4, iter:370] Loss: 0.032 | Acc: 99.194% \n",
      "[epoch:4, iter:371] Loss: 0.033 | Acc: 99.111% \n",
      "[epoch:4, iter:372] Loss: 0.034 | Acc: 99.100% \n",
      "[epoch:4, iter:373] Loss: 0.035 | Acc: 99.090% \n",
      "[epoch:4, iter:374] Loss: 0.035 | Acc: 99.081% \n",
      "[epoch:4, iter:375] Loss: 0.035 | Acc: 99.094% \n",
      "[epoch:4, iter:376] Loss: 0.035 | Acc: 99.062% \n",
      "[epoch:4, iter:377] Loss: 0.035 | Acc: 99.054% \n",
      "[epoch:4, iter:378] Loss: 0.035 | Acc: 99.067% \n",
      "[epoch:4, iter:379] Loss: 0.036 | Acc: 99.058% \n",
      "[epoch:4, iter:380] Loss: 0.036 | Acc: 99.050% \n",
      "[epoch:4, iter:381] Loss: 0.040 | Acc: 98.917% \n",
      "[epoch:4, iter:382] Loss: 0.041 | Acc: 98.910% \n",
      "[epoch:4, iter:383] Loss: 0.040 | Acc: 98.925% \n",
      "[epoch:4, iter:384] Loss: 0.040 | Acc: 98.938% \n",
      "[epoch:4, iter:385] Loss: 0.040 | Acc: 98.932% \n",
      "[epoch:4, iter:386] Loss: 0.040 | Acc: 98.945% \n",
      "[epoch:4, iter:387] Loss: 0.040 | Acc: 98.958% \n",
      "[epoch:4, iter:388] Loss: 0.040 | Acc: 98.933% \n",
      "[epoch:4, iter:389] Loss: 0.040 | Acc: 98.927% \n",
      "[epoch:4, iter:390] Loss: 0.040 | Acc: 98.940% \n",
      "[epoch:4, iter:391] Loss: 0.040 | Acc: 98.952% \n",
      "[epoch:4, iter:392] Loss: 0.040 | Acc: 98.946% \n",
      "[epoch:4, iter:393] Loss: 0.040 | Acc: 98.958% \n",
      "[epoch:4, iter:394] Loss: 0.040 | Acc: 98.952% \n",
      "[epoch:4, iter:395] Loss: 0.040 | Acc: 98.947% \n",
      "[epoch:4, iter:396] Loss: 0.041 | Acc: 98.906% \n",
      "[epoch:4, iter:397] Loss: 0.041 | Acc: 98.901% \n",
      "[epoch:4, iter:398] Loss: 0.042 | Acc: 98.879% \n",
      "[epoch:4, iter:399] Loss: 0.042 | Acc: 98.891% \n",
      "[epoch:4, iter:400] Loss: 0.043 | Acc: 98.853% \n",
      "[epoch:4, iter:401] Loss: 0.043 | Acc: 98.849% \n",
      "[epoch:4, iter:402] Loss: 0.043 | Acc: 98.861% \n",
      "[epoch:4, iter:403] Loss: 0.043 | Acc: 98.856% \n",
      "[epoch:4, iter:404] Loss: 0.042 | Acc: 98.868% \n",
      "[epoch:4, iter:405] Loss: 0.043 | Acc: 98.848% \n",
      "[epoch:4, iter:406] Loss: 0.043 | Acc: 98.844% \n",
      "[epoch:4, iter:407] Loss: 0.043 | Acc: 98.855% \n",
      "[epoch:4, iter:408] Loss: 0.044 | Acc: 98.835% \n",
      "Waiting Val...\n",
      "Val's ac is: 0.000%\n",
      "save epoch 3 model\n",
      "\n",
      "Epoch: 5\n",
      "[epoch:5, iter:409] Loss: 0.098 | Acc: 96.875% \n",
      "[epoch:5, iter:410] Loss: 0.060 | Acc: 98.438% \n",
      "[epoch:5, iter:411] Loss: 0.043 | Acc: 98.958% \n",
      "[epoch:5, iter:412] Loss: 0.048 | Acc: 98.438% \n",
      "[epoch:5, iter:413] Loss: 0.053 | Acc: 98.438% \n",
      "[epoch:5, iter:414] Loss: 0.047 | Acc: 98.698% \n",
      "[epoch:5, iter:415] Loss: 0.047 | Acc: 98.661% \n",
      "[epoch:5, iter:416] Loss: 0.043 | Acc: 98.828% \n",
      "[epoch:5, iter:417] Loss: 0.042 | Acc: 98.785% \n",
      "[epoch:5, iter:418] Loss: 0.042 | Acc: 98.750% \n",
      "[epoch:5, iter:419] Loss: 0.043 | Acc: 98.722% \n",
      "[epoch:5, iter:420] Loss: 0.042 | Acc: 98.698% \n",
      "[epoch:5, iter:421] Loss: 0.039 | Acc: 98.798% \n",
      "[epoch:5, iter:422] Loss: 0.040 | Acc: 98.661% \n",
      "[epoch:5, iter:423] Loss: 0.040 | Acc: 98.750% \n",
      "[epoch:5, iter:424] Loss: 0.039 | Acc: 98.828% \n",
      "[epoch:5, iter:425] Loss: 0.039 | Acc: 98.805% \n",
      "[epoch:5, iter:426] Loss: 0.037 | Acc: 98.872% \n",
      "[epoch:5, iter:427] Loss: 0.042 | Acc: 98.766% \n",
      "[epoch:5, iter:428] Loss: 0.041 | Acc: 98.828% \n",
      "[epoch:5, iter:429] Loss: 0.042 | Acc: 98.661% \n",
      "[epoch:5, iter:430] Loss: 0.040 | Acc: 98.722% \n",
      "[epoch:5, iter:431] Loss: 0.039 | Acc: 98.777% \n",
      "[epoch:5, iter:432] Loss: 0.038 | Acc: 98.828% \n",
      "[epoch:5, iter:433] Loss: 0.039 | Acc: 98.750% \n",
      "[epoch:5, iter:434] Loss: 0.039 | Acc: 98.738% \n",
      "[epoch:5, iter:435] Loss: 0.039 | Acc: 98.727% \n",
      "[epoch:5, iter:436] Loss: 0.038 | Acc: 98.772% \n",
      "[epoch:5, iter:437] Loss: 0.039 | Acc: 98.707% \n",
      "[epoch:5, iter:438] Loss: 0.039 | Acc: 98.698% \n",
      "[epoch:5, iter:439] Loss: 0.039 | Acc: 98.639% \n",
      "[epoch:5, iter:440] Loss: 0.040 | Acc: 98.633% \n",
      "[epoch:5, iter:441] Loss: 0.040 | Acc: 98.674% \n",
      "[epoch:5, iter:442] Loss: 0.041 | Acc: 98.667% \n",
      "[epoch:5, iter:443] Loss: 0.040 | Acc: 98.705% \n",
      "[epoch:5, iter:444] Loss: 0.039 | Acc: 98.741% \n",
      "[epoch:5, iter:445] Loss: 0.040 | Acc: 98.733% \n",
      "[epoch:5, iter:446] Loss: 0.044 | Acc: 98.602% \n",
      "[epoch:5, iter:447] Loss: 0.045 | Acc: 98.558% \n",
      "[epoch:5, iter:448] Loss: 0.044 | Acc: 98.594% \n",
      "[epoch:5, iter:449] Loss: 0.043 | Acc: 98.628% \n",
      "[epoch:5, iter:450] Loss: 0.043 | Acc: 98.661% \n",
      "[epoch:5, iter:451] Loss: 0.042 | Acc: 98.692% \n",
      "[epoch:5, iter:452] Loss: 0.041 | Acc: 98.722% \n",
      "[epoch:5, iter:453] Loss: 0.041 | Acc: 98.750% \n",
      "[epoch:5, iter:454] Loss: 0.041 | Acc: 98.777% \n",
      "[epoch:5, iter:455] Loss: 0.041 | Acc: 98.737% \n",
      "[epoch:5, iter:456] Loss: 0.040 | Acc: 98.763% \n",
      "[epoch:5, iter:457] Loss: 0.040 | Acc: 98.756% \n",
      "[epoch:5, iter:458] Loss: 0.041 | Acc: 98.750% \n",
      "[epoch:5, iter:459] Loss: 0.042 | Acc: 98.713% \n",
      "[epoch:5, iter:460] Loss: 0.043 | Acc: 98.678% \n",
      "[epoch:5, iter:461] Loss: 0.043 | Acc: 98.673% \n",
      "[epoch:5, iter:462] Loss: 0.043 | Acc: 98.698% \n",
      "[epoch:5, iter:463] Loss: 0.043 | Acc: 98.693% \n",
      "[epoch:5, iter:464] Loss: 0.043 | Acc: 98.661% \n",
      "[epoch:5, iter:465] Loss: 0.042 | Acc: 98.684% \n",
      "[epoch:5, iter:466] Loss: 0.043 | Acc: 98.680% \n",
      "[epoch:5, iter:467] Loss: 0.043 | Acc: 98.649% \n",
      "[epoch:5, iter:468] Loss: 0.044 | Acc: 98.646% \n",
      "[epoch:5, iter:469] Loss: 0.044 | Acc: 98.668% \n",
      "[epoch:5, iter:470] Loss: 0.043 | Acc: 98.690% \n",
      "[epoch:5, iter:471] Loss: 0.044 | Acc: 98.661% \n",
      "[epoch:5, iter:472] Loss: 0.044 | Acc: 98.682% \n",
      "[epoch:5, iter:473] Loss: 0.044 | Acc: 98.654% \n",
      "[epoch:5, iter:474] Loss: 0.044 | Acc: 98.603% \n",
      "[epoch:5, iter:475] Loss: 0.045 | Acc: 98.554% \n",
      "[epoch:5, iter:476] Loss: 0.045 | Acc: 98.552% \n",
      "[epoch:5, iter:477] Loss: 0.047 | Acc: 98.528% \n",
      "[epoch:5, iter:478] Loss: 0.047 | Acc: 98.482% \n",
      "[epoch:5, iter:479] Loss: 0.047 | Acc: 98.504% \n",
      "[epoch:5, iter:480] Loss: 0.047 | Acc: 98.503% \n",
      "[epoch:5, iter:481] Loss: 0.047 | Acc: 98.523% \n",
      "[epoch:5, iter:482] Loss: 0.047 | Acc: 98.501% \n",
      "[epoch:5, iter:483] Loss: 0.047 | Acc: 98.521% \n",
      "[epoch:5, iter:484] Loss: 0.047 | Acc: 98.499% \n",
      "[epoch:5, iter:485] Loss: 0.046 | Acc: 98.519% \n",
      "[epoch:5, iter:486] Loss: 0.046 | Acc: 98.538% \n",
      "[epoch:5, iter:487] Loss: 0.046 | Acc: 98.556% \n",
      "[epoch:5, iter:488] Loss: 0.048 | Acc: 98.496% \n",
      "[epoch:5, iter:489] Loss: 0.048 | Acc: 98.515% \n",
      "[epoch:5, iter:490] Loss: 0.048 | Acc: 98.514% \n",
      "[epoch:5, iter:491] Loss: 0.047 | Acc: 98.532% \n",
      "[epoch:5, iter:492] Loss: 0.048 | Acc: 98.512% \n",
      "[epoch:5, iter:493] Loss: 0.048 | Acc: 98.511% \n",
      "[epoch:5, iter:494] Loss: 0.048 | Acc: 98.510% \n",
      "[epoch:5, iter:495] Loss: 0.048 | Acc: 98.509% \n",
      "[epoch:5, iter:496] Loss: 0.048 | Acc: 98.491% \n",
      "[epoch:5, iter:497] Loss: 0.048 | Acc: 98.490% \n",
      "[epoch:5, iter:498] Loss: 0.047 | Acc: 98.507% \n",
      "[epoch:5, iter:499] Loss: 0.047 | Acc: 98.506% \n",
      "[epoch:5, iter:500] Loss: 0.047 | Acc: 98.522% \n",
      "[epoch:5, iter:501] Loss: 0.047 | Acc: 98.538% \n",
      "[epoch:5, iter:502] Loss: 0.047 | Acc: 98.504% \n",
      "[epoch:5, iter:503] Loss: 0.047 | Acc: 98.503% \n",
      "[epoch:5, iter:504] Loss: 0.047 | Acc: 98.519% \n",
      "[epoch:5, iter:505] Loss: 0.047 | Acc: 98.534% \n",
      "[epoch:5, iter:506] Loss: 0.047 | Acc: 98.533% \n",
      "[epoch:5, iter:507] Loss: 0.046 | Acc: 98.548% \n",
      "[epoch:5, iter:508] Loss: 0.047 | Acc: 98.547% \n",
      "[epoch:5, iter:509] Loss: 0.047 | Acc: 98.561% \n",
      "[epoch:5, iter:510] Loss: 0.047 | Acc: 98.543% \n",
      "Waiting Val...\n",
      "Val's ac is: 0.000%\n",
      "save epoch 4 model\n",
      "\n",
      "Epoch: 6\n",
      "[epoch:6, iter:511] Loss: 0.043 | Acc: 98.438% \n",
      "[epoch:6, iter:512] Loss: 0.039 | Acc: 98.438% \n",
      "[epoch:6, iter:513] Loss: 0.051 | Acc: 98.438% \n",
      "[epoch:6, iter:514] Loss: 0.041 | Acc: 98.828% \n",
      "[epoch:6, iter:515] Loss: 0.041 | Acc: 98.750% \n",
      "[epoch:6, iter:516] Loss: 0.040 | Acc: 98.438% \n",
      "[epoch:6, iter:517] Loss: 0.036 | Acc: 98.661% \n",
      "[epoch:6, iter:518] Loss: 0.033 | Acc: 98.828% \n",
      "[epoch:6, iter:519] Loss: 0.030 | Acc: 98.958% \n",
      "[epoch:6, iter:520] Loss: 0.031 | Acc: 98.906% \n",
      "[epoch:6, iter:521] Loss: 0.032 | Acc: 98.864% \n",
      "[epoch:6, iter:522] Loss: 0.031 | Acc: 98.958% \n",
      "[epoch:6, iter:523] Loss: 0.036 | Acc: 98.918% \n",
      "[epoch:6, iter:524] Loss: 0.038 | Acc: 98.884% \n",
      "[epoch:6, iter:525] Loss: 0.039 | Acc: 98.854% \n",
      "[epoch:6, iter:526] Loss: 0.039 | Acc: 98.926% \n",
      "[epoch:6, iter:527] Loss: 0.037 | Acc: 98.989% \n",
      "[epoch:6, iter:528] Loss: 0.036 | Acc: 99.045% \n",
      "[epoch:6, iter:529] Loss: 0.036 | Acc: 99.095% \n",
      "[epoch:6, iter:530] Loss: 0.035 | Acc: 99.141% \n",
      "[epoch:6, iter:531] Loss: 0.034 | Acc: 99.182% \n",
      "[epoch:6, iter:532] Loss: 0.032 | Acc: 99.219% \n",
      "[epoch:6, iter:533] Loss: 0.031 | Acc: 99.253% \n",
      "[epoch:6, iter:534] Loss: 0.030 | Acc: 99.284% \n",
      "[epoch:6, iter:535] Loss: 0.030 | Acc: 99.312% \n",
      "[epoch:6, iter:536] Loss: 0.030 | Acc: 99.339% \n",
      "[epoch:6, iter:537] Loss: 0.029 | Acc: 99.363% \n",
      "[epoch:6, iter:538] Loss: 0.028 | Acc: 99.386% \n",
      "[epoch:6, iter:539] Loss: 0.029 | Acc: 99.407% \n",
      "[epoch:6, iter:540] Loss: 0.028 | Acc: 99.427% \n",
      "[epoch:6, iter:541] Loss: 0.028 | Acc: 99.395% \n",
      "[epoch:6, iter:542] Loss: 0.028 | Acc: 99.414% \n",
      "[epoch:6, iter:543] Loss: 0.029 | Acc: 99.290% \n",
      "[epoch:6, iter:544] Loss: 0.030 | Acc: 99.219% \n",
      "[epoch:6, iter:545] Loss: 0.032 | Acc: 99.062% \n",
      "[epoch:6, iter:546] Loss: 0.031 | Acc: 99.089% \n",
      "[epoch:6, iter:547] Loss: 0.031 | Acc: 99.113% \n",
      "[epoch:6, iter:548] Loss: 0.030 | Acc: 99.137% \n",
      "[epoch:6, iter:549] Loss: 0.030 | Acc: 99.159% \n",
      "[epoch:6, iter:550] Loss: 0.030 | Acc: 99.141% \n",
      "[epoch:6, iter:551] Loss: 0.029 | Acc: 99.162% \n",
      "[epoch:6, iter:552] Loss: 0.029 | Acc: 99.144% \n",
      "[epoch:6, iter:553] Loss: 0.029 | Acc: 99.164% \n",
      "[epoch:6, iter:554] Loss: 0.029 | Acc: 99.183% \n",
      "[epoch:6, iter:555] Loss: 0.028 | Acc: 99.201% \n",
      "[epoch:6, iter:556] Loss: 0.028 | Acc: 99.219% \n",
      "[epoch:6, iter:557] Loss: 0.028 | Acc: 99.235% \n",
      "[epoch:6, iter:558] Loss: 0.028 | Acc: 99.219% \n",
      "[epoch:6, iter:559] Loss: 0.029 | Acc: 99.203% \n",
      "[epoch:6, iter:560] Loss: 0.028 | Acc: 99.219% \n",
      "[epoch:6, iter:561] Loss: 0.028 | Acc: 99.234% \n",
      "[epoch:6, iter:562] Loss: 0.028 | Acc: 99.219% \n",
      "[epoch:6, iter:563] Loss: 0.028 | Acc: 99.233% \n",
      "[epoch:6, iter:564] Loss: 0.029 | Acc: 99.219% \n",
      "[epoch:6, iter:565] Loss: 0.028 | Acc: 99.233% \n",
      "[epoch:6, iter:566] Loss: 0.028 | Acc: 99.247% \n",
      "[epoch:6, iter:567] Loss: 0.028 | Acc: 99.260% \n",
      "[epoch:6, iter:568] Loss: 0.027 | Acc: 99.273% \n",
      "[epoch:6, iter:569] Loss: 0.027 | Acc: 99.285% \n",
      "[epoch:6, iter:570] Loss: 0.027 | Acc: 99.271% \n",
      "[epoch:6, iter:571] Loss: 0.027 | Acc: 99.283% \n",
      "[epoch:6, iter:572] Loss: 0.027 | Acc: 99.294% \n",
      "[epoch:6, iter:573] Loss: 0.026 | Acc: 99.306% \n",
      "[epoch:6, iter:574] Loss: 0.026 | Acc: 99.316% \n",
      "[epoch:6, iter:575] Loss: 0.026 | Acc: 99.303% \n",
      "[epoch:6, iter:576] Loss: 0.027 | Acc: 99.290% \n",
      "[epoch:6, iter:577] Loss: 0.028 | Acc: 99.207% \n",
      "[epoch:6, iter:578] Loss: 0.028 | Acc: 99.196% \n",
      "[epoch:6, iter:579] Loss: 0.028 | Acc: 99.207% \n",
      "[epoch:6, iter:580] Loss: 0.029 | Acc: 99.196% \n",
      "[epoch:6, iter:581] Loss: 0.028 | Acc: 99.208% \n",
      "[epoch:6, iter:582] Loss: 0.028 | Acc: 99.197% \n",
      "[epoch:6, iter:583] Loss: 0.028 | Acc: 99.208% \n",
      "[epoch:6, iter:584] Loss: 0.028 | Acc: 99.219% \n",
      "[epoch:6, iter:585] Loss: 0.028 | Acc: 99.229% \n",
      "[epoch:6, iter:586] Loss: 0.028 | Acc: 99.219% \n",
      "[epoch:6, iter:587] Loss: 0.028 | Acc: 99.229% \n",
      "[epoch:6, iter:588] Loss: 0.029 | Acc: 99.199% \n",
      "[epoch:6, iter:589] Loss: 0.028 | Acc: 99.209% \n",
      "[epoch:6, iter:590] Loss: 0.028 | Acc: 99.219% \n",
      "[epoch:6, iter:591] Loss: 0.028 | Acc: 99.228% \n",
      "[epoch:6, iter:592] Loss: 0.028 | Acc: 99.219% \n",
      "[epoch:6, iter:593] Loss: 0.028 | Acc: 99.209% \n",
      "[epoch:6, iter:594] Loss: 0.029 | Acc: 99.200% \n",
      "[epoch:6, iter:595] Loss: 0.029 | Acc: 99.191% \n",
      "[epoch:6, iter:596] Loss: 0.029 | Acc: 99.164% \n",
      "[epoch:6, iter:597] Loss: 0.029 | Acc: 99.174% \n",
      "[epoch:6, iter:598] Loss: 0.029 | Acc: 99.183% \n",
      "[epoch:6, iter:599] Loss: 0.029 | Acc: 99.175% \n",
      "[epoch:6, iter:600] Loss: 0.029 | Acc: 99.149% \n",
      "[epoch:6, iter:601] Loss: 0.029 | Acc: 99.159% \n",
      "[epoch:6, iter:602] Loss: 0.029 | Acc: 99.168% \n",
      "[epoch:6, iter:603] Loss: 0.029 | Acc: 99.177% \n",
      "[epoch:6, iter:604] Loss: 0.029 | Acc: 99.186% \n",
      "[epoch:6, iter:605] Loss: 0.029 | Acc: 99.178% \n",
      "[epoch:6, iter:606] Loss: 0.029 | Acc: 99.154% \n",
      "[epoch:6, iter:607] Loss: 0.029 | Acc: 99.146% \n",
      "[epoch:6, iter:608] Loss: 0.029 | Acc: 99.155% \n",
      "[epoch:6, iter:609] Loss: 0.030 | Acc: 99.148% \n",
      "[epoch:6, iter:610] Loss: 0.030 | Acc: 99.141% \n",
      "[epoch:6, iter:611] Loss: 0.030 | Acc: 99.118% \n",
      "[epoch:6, iter:612] Loss: 0.030 | Acc: 99.126% \n",
      "Waiting Val...\n",
      "Val's ac is: 0.000%\n",
      "save epoch 5 model\n",
      "\n",
      "Epoch: 7\n",
      "[epoch:7, iter:613] Loss: 0.006 | Acc: 100.000% \n",
      "[epoch:7, iter:614] Loss: 0.010 | Acc: 100.000% \n",
      "[epoch:7, iter:615] Loss: 0.014 | Acc: 100.000% \n",
      "[epoch:7, iter:616] Loss: 0.015 | Acc: 100.000% \n",
      "[epoch:7, iter:617] Loss: 0.014 | Acc: 100.000% \n",
      "[epoch:7, iter:618] Loss: 0.017 | Acc: 100.000% \n",
      "[epoch:7, iter:619] Loss: 0.015 | Acc: 100.000% \n",
      "[epoch:7, iter:620] Loss: 0.020 | Acc: 99.805% \n",
      "[epoch:7, iter:621] Loss: 0.023 | Acc: 99.653% \n",
      "[epoch:7, iter:622] Loss: 0.021 | Acc: 99.688% \n",
      "[epoch:7, iter:623] Loss: 0.024 | Acc: 99.432% \n",
      "[epoch:7, iter:624] Loss: 0.023 | Acc: 99.479% \n",
      "[epoch:7, iter:625] Loss: 0.022 | Acc: 99.519% \n",
      "[epoch:7, iter:626] Loss: 0.025 | Acc: 99.219% \n",
      "[epoch:7, iter:627] Loss: 0.026 | Acc: 99.271% \n",
      "[epoch:7, iter:628] Loss: 0.025 | Acc: 99.219% \n",
      "[epoch:7, iter:629] Loss: 0.028 | Acc: 99.081% \n",
      "[epoch:7, iter:630] Loss: 0.031 | Acc: 98.958% \n",
      "[epoch:7, iter:631] Loss: 0.031 | Acc: 98.931% \n",
      "[epoch:7, iter:632] Loss: 0.032 | Acc: 98.906% \n",
      "[epoch:7, iter:633] Loss: 0.031 | Acc: 98.884% \n",
      "[epoch:7, iter:634] Loss: 0.030 | Acc: 98.935% \n",
      "[epoch:7, iter:635] Loss: 0.029 | Acc: 98.981% \n",
      "[epoch:7, iter:636] Loss: 0.028 | Acc: 99.023% \n",
      "[epoch:7, iter:637] Loss: 0.028 | Acc: 99.062% \n",
      "[epoch:7, iter:638] Loss: 0.028 | Acc: 99.099% \n",
      "[epoch:7, iter:639] Loss: 0.027 | Acc: 99.074% \n",
      "[epoch:7, iter:640] Loss: 0.027 | Acc: 99.051% \n",
      "[epoch:7, iter:641] Loss: 0.027 | Acc: 99.084% \n",
      "[epoch:7, iter:642] Loss: 0.026 | Acc: 99.115% \n",
      "[epoch:7, iter:643] Loss: 0.026 | Acc: 99.143% \n",
      "[epoch:7, iter:644] Loss: 0.025 | Acc: 99.170% \n",
      "[epoch:7, iter:645] Loss: 0.024 | Acc: 99.195% \n",
      "[epoch:7, iter:646] Loss: 0.025 | Acc: 99.173% \n",
      "[epoch:7, iter:647] Loss: 0.024 | Acc: 99.196% \n",
      "[epoch:7, iter:648] Loss: 0.025 | Acc: 99.175% \n",
      "[epoch:7, iter:649] Loss: 0.024 | Acc: 99.198% \n",
      "[epoch:7, iter:650] Loss: 0.024 | Acc: 99.219% \n",
      "[epoch:7, iter:651] Loss: 0.024 | Acc: 99.239% \n",
      "[epoch:7, iter:652] Loss: 0.023 | Acc: 99.258% \n",
      "[epoch:7, iter:653] Loss: 0.024 | Acc: 99.238% \n",
      "[epoch:7, iter:654] Loss: 0.024 | Acc: 99.256% \n",
      "[epoch:7, iter:655] Loss: 0.024 | Acc: 99.273% \n",
      "[epoch:7, iter:656] Loss: 0.024 | Acc: 99.254% \n",
      "[epoch:7, iter:657] Loss: 0.024 | Acc: 99.236% \n",
      "[epoch:7, iter:658] Loss: 0.024 | Acc: 99.253% \n",
      "[epoch:7, iter:659] Loss: 0.024 | Acc: 99.235% \n",
      "[epoch:7, iter:660] Loss: 0.025 | Acc: 99.186% \n",
      "[epoch:7, iter:661] Loss: 0.026 | Acc: 99.171% \n",
      "[epoch:7, iter:662] Loss: 0.025 | Acc: 99.188% \n",
      "[epoch:7, iter:663] Loss: 0.026 | Acc: 99.173% \n",
      "[epoch:7, iter:664] Loss: 0.026 | Acc: 99.159% \n",
      "[epoch:7, iter:665] Loss: 0.026 | Acc: 99.145% \n",
      "[epoch:7, iter:666] Loss: 0.026 | Acc: 99.161% \n",
      "[epoch:7, iter:667] Loss: 0.026 | Acc: 99.176% \n",
      "[epoch:7, iter:668] Loss: 0.025 | Acc: 99.191% \n",
      "[epoch:7, iter:669] Loss: 0.026 | Acc: 99.205% \n",
      "[epoch:7, iter:670] Loss: 0.026 | Acc: 99.219% \n",
      "[epoch:7, iter:671] Loss: 0.026 | Acc: 99.206% \n",
      "[epoch:7, iter:672] Loss: 0.026 | Acc: 99.193% \n",
      "[epoch:7, iter:673] Loss: 0.026 | Acc: 99.180% \n",
      "[epoch:7, iter:674] Loss: 0.027 | Acc: 99.168% \n",
      "[epoch:7, iter:675] Loss: 0.027 | Acc: 99.157% \n",
      "[epoch:7, iter:676] Loss: 0.028 | Acc: 99.097% \n",
      "[epoch:7, iter:677] Loss: 0.028 | Acc: 99.111% \n",
      "[epoch:7, iter:678] Loss: 0.028 | Acc: 99.124% \n",
      "[epoch:7, iter:679] Loss: 0.028 | Acc: 99.090% \n",
      "[epoch:7, iter:680] Loss: 0.029 | Acc: 99.035% \n",
      "[epoch:7, iter:681] Loss: 0.029 | Acc: 99.049% \n",
      "[epoch:7, iter:682] Loss: 0.029 | Acc: 99.062% \n",
      "[epoch:7, iter:683] Loss: 0.030 | Acc: 99.054% \n",
      "[epoch:7, iter:684] Loss: 0.030 | Acc: 99.067% \n",
      "[epoch:7, iter:685] Loss: 0.030 | Acc: 99.058% \n",
      "[epoch:7, iter:686] Loss: 0.030 | Acc: 99.071% \n",
      "[epoch:7, iter:687] Loss: 0.030 | Acc: 99.083% \n",
      "[epoch:7, iter:688] Loss: 0.030 | Acc: 99.075% \n",
      "[epoch:7, iter:689] Loss: 0.030 | Acc: 99.046% \n",
      "[epoch:7, iter:690] Loss: 0.030 | Acc: 99.058% \n",
      "[epoch:7, iter:691] Loss: 0.030 | Acc: 99.070% \n",
      "[epoch:7, iter:692] Loss: 0.030 | Acc: 99.082% \n",
      "[epoch:7, iter:693] Loss: 0.030 | Acc: 99.093% \n",
      "[epoch:7, iter:694] Loss: 0.030 | Acc: 99.066% \n",
      "[epoch:7, iter:695] Loss: 0.030 | Acc: 99.078% \n",
      "[epoch:7, iter:696] Loss: 0.030 | Acc: 99.089% \n",
      "[epoch:7, iter:697] Loss: 0.030 | Acc: 99.081% \n",
      "[epoch:7, iter:698] Loss: 0.030 | Acc: 99.092% \n",
      "[epoch:7, iter:699] Loss: 0.030 | Acc: 99.084% \n",
      "[epoch:7, iter:700] Loss: 0.030 | Acc: 99.077% \n",
      "[epoch:7, iter:701] Loss: 0.030 | Acc: 99.070% \n",
      "[epoch:7, iter:702] Loss: 0.030 | Acc: 99.062% \n",
      "[epoch:7, iter:703] Loss: 0.032 | Acc: 99.004% \n",
      "[epoch:7, iter:704] Loss: 0.032 | Acc: 99.015% \n",
      "[epoch:7, iter:705] Loss: 0.032 | Acc: 99.009% \n",
      "[epoch:7, iter:706] Loss: 0.033 | Acc: 98.969% \n",
      "[epoch:7, iter:707] Loss: 0.034 | Acc: 98.931% \n",
      "[epoch:7, iter:708] Loss: 0.034 | Acc: 98.910% \n",
      "[epoch:7, iter:709] Loss: 0.035 | Acc: 98.840% \n",
      "[epoch:7, iter:710] Loss: 0.035 | Acc: 98.852% \n",
      "[epoch:7, iter:711] Loss: 0.035 | Acc: 98.848% \n",
      "[epoch:7, iter:712] Loss: 0.035 | Acc: 98.859% \n",
      "[epoch:7, iter:713] Loss: 0.035 | Acc: 98.855% \n",
      "[epoch:7, iter:714] Loss: 0.036 | Acc: 98.835% \n",
      "Waiting Val...\n",
      "Val's ac is: 0.000%\n",
      "save epoch 6 model\n",
      "\n",
      "Epoch: 8\n",
      "[epoch:8, iter:715] Loss: 0.030 | Acc: 98.438% \n",
      "[epoch:8, iter:716] Loss: 0.024 | Acc: 99.219% \n",
      "[epoch:8, iter:717] Loss: 0.047 | Acc: 98.438% \n",
      "[epoch:8, iter:718] Loss: 0.053 | Acc: 98.047% \n",
      "[epoch:8, iter:719] Loss: 0.060 | Acc: 98.125% \n",
      "[epoch:8, iter:720] Loss: 0.066 | Acc: 97.917% \n",
      "[epoch:8, iter:721] Loss: 0.061 | Acc: 98.214% \n",
      "[epoch:8, iter:722] Loss: 0.059 | Acc: 98.242% \n",
      "[epoch:8, iter:723] Loss: 0.054 | Acc: 98.438% \n",
      "[epoch:8, iter:724] Loss: 0.066 | Acc: 97.969% \n",
      "[epoch:8, iter:725] Loss: 0.061 | Acc: 98.153% \n",
      "[epoch:8, iter:726] Loss: 0.072 | Acc: 97.786% \n",
      "[epoch:8, iter:727] Loss: 0.069 | Acc: 97.837% \n",
      "[epoch:8, iter:728] Loss: 0.084 | Acc: 97.321% \n",
      "[epoch:8, iter:729] Loss: 0.081 | Acc: 97.396% \n",
      "[epoch:8, iter:730] Loss: 0.078 | Acc: 97.461% \n",
      "[epoch:8, iter:731] Loss: 0.076 | Acc: 97.518% \n",
      "[epoch:8, iter:732] Loss: 0.072 | Acc: 97.656% \n",
      "[epoch:8, iter:733] Loss: 0.073 | Acc: 97.697% \n",
      "[epoch:8, iter:734] Loss: 0.075 | Acc: 97.656% \n",
      "[epoch:8, iter:735] Loss: 0.075 | Acc: 97.619% \n",
      "[epoch:8, iter:736] Loss: 0.074 | Acc: 97.656% \n",
      "[epoch:8, iter:737] Loss: 0.073 | Acc: 97.690% \n",
      "[epoch:8, iter:738] Loss: 0.071 | Acc: 97.786% \n",
      "[epoch:8, iter:739] Loss: 0.072 | Acc: 97.750% \n",
      "[epoch:8, iter:740] Loss: 0.073 | Acc: 97.716% \n",
      "[epoch:8, iter:741] Loss: 0.078 | Acc: 97.512% \n",
      "[epoch:8, iter:742] Loss: 0.087 | Acc: 97.321% \n",
      "[epoch:8, iter:743] Loss: 0.084 | Acc: 97.414% \n",
      "[epoch:8, iter:744] Loss: 0.084 | Acc: 97.396% \n",
      "[epoch:8, iter:745] Loss: 0.085 | Acc: 97.278% \n",
      "[epoch:8, iter:746] Loss: 0.083 | Acc: 97.314% \n",
      "[epoch:8, iter:747] Loss: 0.084 | Acc: 97.254% \n",
      "[epoch:8, iter:748] Loss: 0.083 | Acc: 97.289% \n",
      "[epoch:8, iter:749] Loss: 0.084 | Acc: 97.232% \n",
      "[epoch:8, iter:750] Loss: 0.083 | Acc: 97.266% \n",
      "[epoch:8, iter:751] Loss: 0.081 | Acc: 97.340% \n",
      "[epoch:8, iter:752] Loss: 0.080 | Acc: 97.368% \n",
      "[epoch:8, iter:753] Loss: 0.080 | Acc: 97.356% \n",
      "[epoch:8, iter:754] Loss: 0.078 | Acc: 97.422% \n",
      "[epoch:8, iter:755] Loss: 0.080 | Acc: 97.409% \n",
      "[epoch:8, iter:756] Loss: 0.081 | Acc: 97.396% \n",
      "[epoch:8, iter:757] Loss: 0.080 | Acc: 97.420% \n",
      "[epoch:8, iter:758] Loss: 0.079 | Acc: 97.479% \n",
      "[epoch:8, iter:759] Loss: 0.082 | Acc: 97.396% \n",
      "[epoch:8, iter:760] Loss: 0.081 | Acc: 97.418% \n",
      "[epoch:8, iter:761] Loss: 0.080 | Acc: 97.440% \n",
      "[epoch:8, iter:762] Loss: 0.079 | Acc: 97.461% \n",
      "[epoch:8, iter:763] Loss: 0.080 | Acc: 97.449% \n",
      "[epoch:8, iter:764] Loss: 0.080 | Acc: 97.375% \n",
      "[epoch:8, iter:765] Loss: 0.079 | Acc: 97.426% \n",
      "[epoch:8, iter:766] Loss: 0.080 | Acc: 97.386% \n",
      "[epoch:8, iter:767] Loss: 0.079 | Acc: 97.406% \n",
      "[epoch:8, iter:768] Loss: 0.079 | Acc: 97.425% \n",
      "[epoch:8, iter:769] Loss: 0.081 | Acc: 97.386% \n",
      "[epoch:8, iter:770] Loss: 0.080 | Acc: 97.405% \n",
      "[epoch:8, iter:771] Loss: 0.080 | Acc: 97.396% \n",
      "[epoch:8, iter:772] Loss: 0.079 | Acc: 97.414% \n",
      "[epoch:8, iter:773] Loss: 0.079 | Acc: 97.431% \n",
      "[epoch:8, iter:774] Loss: 0.079 | Acc: 97.396% \n",
      "[epoch:8, iter:775] Loss: 0.079 | Acc: 97.336% \n",
      "[epoch:8, iter:776] Loss: 0.078 | Acc: 97.379% \n",
      "[epoch:8, iter:777] Loss: 0.080 | Acc: 97.371% \n",
      "[epoch:8, iter:778] Loss: 0.080 | Acc: 97.339% \n",
      "[epoch:8, iter:779] Loss: 0.080 | Acc: 97.332% \n",
      "[epoch:8, iter:780] Loss: 0.081 | Acc: 97.301% \n",
      "[epoch:8, iter:781] Loss: 0.081 | Acc: 97.318% \n",
      "[epoch:8, iter:782] Loss: 0.080 | Acc: 97.335% \n",
      "[epoch:8, iter:783] Loss: 0.081 | Acc: 97.328% \n",
      "[epoch:8, iter:784] Loss: 0.081 | Acc: 97.344% \n",
      "[epoch:8, iter:785] Loss: 0.081 | Acc: 97.337% \n",
      "[epoch:8, iter:786] Loss: 0.081 | Acc: 97.352% \n",
      "[epoch:8, iter:787] Loss: 0.081 | Acc: 97.303% \n",
      "[epoch:8, iter:788] Loss: 0.082 | Acc: 97.297% \n",
      "[epoch:8, iter:789] Loss: 0.082 | Acc: 97.292% \n",
      "[epoch:8, iter:790] Loss: 0.081 | Acc: 97.307% \n",
      "[epoch:8, iter:791] Loss: 0.081 | Acc: 97.321% \n",
      "[epoch:8, iter:792] Loss: 0.081 | Acc: 97.336% \n",
      "[epoch:8, iter:793] Loss: 0.080 | Acc: 97.369% \n",
      "[epoch:8, iter:794] Loss: 0.079 | Acc: 97.402% \n",
      "[epoch:8, iter:795] Loss: 0.080 | Acc: 97.357% \n",
      "[epoch:8, iter:796] Loss: 0.081 | Acc: 97.332% \n",
      "[epoch:8, iter:797] Loss: 0.083 | Acc: 97.308% \n",
      "[epoch:8, iter:798] Loss: 0.083 | Acc: 97.303% \n",
      "[epoch:8, iter:799] Loss: 0.083 | Acc: 97.279% \n",
      "[epoch:8, iter:800] Loss: 0.083 | Acc: 97.293% \n",
      "[epoch:8, iter:801] Loss: 0.083 | Acc: 97.306% \n",
      "[epoch:8, iter:802] Loss: 0.083 | Acc: 97.319% \n",
      "[epoch:8, iter:803] Loss: 0.082 | Acc: 97.314% \n",
      "[epoch:8, iter:804] Loss: 0.083 | Acc: 97.309% \n",
      "[epoch:8, iter:805] Loss: 0.082 | Acc: 97.321% \n",
      "[epoch:8, iter:806] Loss: 0.085 | Acc: 97.283% \n",
      "[epoch:8, iter:807] Loss: 0.086 | Acc: 97.245% \n",
      "[epoch:8, iter:808] Loss: 0.086 | Acc: 97.241% \n",
      "[epoch:8, iter:809] Loss: 0.086 | Acc: 97.220% \n",
      "[epoch:8, iter:810] Loss: 0.086 | Acc: 97.249% \n",
      "[epoch:8, iter:811] Loss: 0.085 | Acc: 97.278% \n",
      "[epoch:8, iter:812] Loss: 0.085 | Acc: 97.305% \n",
      "[epoch:8, iter:813] Loss: 0.084 | Acc: 97.333% \n",
      "[epoch:8, iter:814] Loss: 0.084 | Acc: 97.328% \n",
      "[epoch:8, iter:815] Loss: 0.085 | Acc: 97.324% \n",
      "[epoch:8, iter:816] Loss: 0.087 | Acc: 97.301% \n",
      "Waiting Val...\n",
      "Val's ac is: 0.000%\n",
      "save epoch 7 model\n",
      "\n",
      "Epoch: 9\n",
      "[epoch:9, iter:817] Loss: 0.015 | Acc: 100.000% \n",
      "[epoch:9, iter:818] Loss: 0.025 | Acc: 99.219% \n",
      "[epoch:9, iter:819] Loss: 0.049 | Acc: 98.438% \n",
      "[epoch:9, iter:820] Loss: 0.075 | Acc: 97.266% \n",
      "[epoch:9, iter:821] Loss: 0.073 | Acc: 97.188% \n",
      "[epoch:9, iter:822] Loss: 0.063 | Acc: 97.656% \n",
      "[epoch:9, iter:823] Loss: 0.060 | Acc: 97.768% \n",
      "[epoch:9, iter:824] Loss: 0.057 | Acc: 97.852% \n",
      "[epoch:9, iter:825] Loss: 0.067 | Acc: 97.743% \n",
      "[epoch:9, iter:826] Loss: 0.074 | Acc: 97.500% \n",
      "[epoch:9, iter:827] Loss: 0.074 | Acc: 97.443% \n",
      "[epoch:9, iter:828] Loss: 0.070 | Acc: 97.656% \n",
      "[epoch:9, iter:829] Loss: 0.076 | Acc: 97.476% \n",
      "[epoch:9, iter:830] Loss: 0.071 | Acc: 97.656% \n",
      "[epoch:9, iter:831] Loss: 0.070 | Acc: 97.604% \n",
      "[epoch:9, iter:832] Loss: 0.070 | Acc: 97.656% \n",
      "[epoch:9, iter:833] Loss: 0.069 | Acc: 97.702% \n",
      "[epoch:9, iter:834] Loss: 0.067 | Acc: 97.743% \n",
      "[epoch:9, iter:835] Loss: 0.065 | Acc: 97.862% \n",
      "[epoch:9, iter:836] Loss: 0.067 | Acc: 97.812% \n",
      "[epoch:9, iter:837] Loss: 0.070 | Acc: 97.842% \n",
      "[epoch:9, iter:838] Loss: 0.070 | Acc: 97.798% \n",
      "[epoch:9, iter:839] Loss: 0.069 | Acc: 97.758% \n",
      "[epoch:9, iter:840] Loss: 0.068 | Acc: 97.786% \n",
      "[epoch:9, iter:841] Loss: 0.067 | Acc: 97.812% \n",
      "[epoch:9, iter:842] Loss: 0.065 | Acc: 97.897% \n",
      "[epoch:9, iter:843] Loss: 0.067 | Acc: 97.917% \n",
      "[epoch:9, iter:844] Loss: 0.065 | Acc: 97.991% \n",
      "[epoch:9, iter:845] Loss: 0.064 | Acc: 98.006% \n",
      "[epoch:9, iter:846] Loss: 0.067 | Acc: 97.969% \n",
      "[epoch:9, iter:847] Loss: 0.067 | Acc: 97.883% \n",
      "[epoch:9, iter:848] Loss: 0.067 | Acc: 97.852% \n",
      "[epoch:9, iter:849] Loss: 0.066 | Acc: 97.917% \n",
      "[epoch:9, iter:850] Loss: 0.064 | Acc: 97.978% \n",
      "[epoch:9, iter:851] Loss: 0.064 | Acc: 97.991% \n",
      "[epoch:9, iter:852] Loss: 0.064 | Acc: 98.047% \n",
      "[epoch:9, iter:853] Loss: 0.062 | Acc: 98.100% \n",
      "[epoch:9, iter:854] Loss: 0.061 | Acc: 98.109% \n",
      "[epoch:9, iter:855] Loss: 0.061 | Acc: 98.117% \n",
      "[epoch:9, iter:856] Loss: 0.061 | Acc: 98.086% \n",
      "[epoch:9, iter:857] Loss: 0.060 | Acc: 98.133% \n",
      "[epoch:9, iter:858] Loss: 0.060 | Acc: 98.103% \n",
      "[epoch:9, iter:859] Loss: 0.061 | Acc: 98.074% \n",
      "[epoch:9, iter:860] Loss: 0.061 | Acc: 98.082% \n",
      "[epoch:9, iter:861] Loss: 0.061 | Acc: 98.090% \n",
      "[epoch:9, iter:862] Loss: 0.060 | Acc: 98.132% \n",
      "[epoch:9, iter:863] Loss: 0.060 | Acc: 98.138% \n",
      "[epoch:9, iter:864] Loss: 0.062 | Acc: 98.047% \n",
      "[epoch:9, iter:865] Loss: 0.061 | Acc: 98.055% \n",
      "[epoch:9, iter:866] Loss: 0.061 | Acc: 98.062% \n",
      "[epoch:9, iter:867] Loss: 0.060 | Acc: 98.070% \n",
      "[epoch:9, iter:868] Loss: 0.061 | Acc: 98.077% \n",
      "[epoch:9, iter:869] Loss: 0.060 | Acc: 98.113% \n",
      "[epoch:9, iter:870] Loss: 0.066 | Acc: 98.032% \n",
      "[epoch:9, iter:871] Loss: 0.065 | Acc: 98.040% \n",
      "[epoch:9, iter:872] Loss: 0.064 | Acc: 98.075% \n",
      "[epoch:9, iter:873] Loss: 0.063 | Acc: 98.109% \n",
      "[epoch:9, iter:874] Loss: 0.063 | Acc: 98.087% \n",
      "[epoch:9, iter:875] Loss: 0.063 | Acc: 98.093% \n",
      "[epoch:9, iter:876] Loss: 0.062 | Acc: 98.125% \n",
      "[epoch:9, iter:877] Loss: 0.062 | Acc: 98.105% \n",
      "[epoch:9, iter:878] Loss: 0.062 | Acc: 98.135% \n",
      "[epoch:9, iter:879] Loss: 0.062 | Acc: 98.140% \n",
      "[epoch:9, iter:880] Loss: 0.062 | Acc: 98.169% \n",
      "[epoch:9, iter:881] Loss: 0.062 | Acc: 98.149% \n",
      "[epoch:9, iter:882] Loss: 0.062 | Acc: 98.153% \n",
      "[epoch:9, iter:883] Loss: 0.061 | Acc: 98.181% \n",
      "[epoch:9, iter:884] Loss: 0.061 | Acc: 98.208% \n",
      "[epoch:9, iter:885] Loss: 0.060 | Acc: 98.234% \n",
      "[epoch:9, iter:886] Loss: 0.060 | Acc: 98.214% \n",
      "[epoch:9, iter:887] Loss: 0.060 | Acc: 98.239% \n",
      "[epoch:9, iter:888] Loss: 0.061 | Acc: 98.199% \n",
      "[epoch:9, iter:889] Loss: 0.062 | Acc: 98.181% \n",
      "[epoch:9, iter:890] Loss: 0.061 | Acc: 98.184% \n",
      "[epoch:9, iter:891] Loss: 0.061 | Acc: 98.188% \n",
      "[epoch:9, iter:892] Loss: 0.061 | Acc: 98.170% \n",
      "[epoch:9, iter:893] Loss: 0.062 | Acc: 98.113% \n",
      "[epoch:9, iter:894] Loss: 0.061 | Acc: 98.117% \n",
      "[epoch:9, iter:895] Loss: 0.061 | Acc: 98.141% \n",
      "[epoch:9, iter:896] Loss: 0.061 | Acc: 98.145% \n",
      "[epoch:9, iter:897] Loss: 0.060 | Acc: 98.167% \n",
      "[epoch:9, iter:898] Loss: 0.060 | Acc: 98.190% \n",
      "[epoch:9, iter:899] Loss: 0.059 | Acc: 98.212% \n",
      "[epoch:9, iter:900] Loss: 0.060 | Acc: 98.196% \n",
      "[epoch:9, iter:901] Loss: 0.059 | Acc: 98.217% \n",
      "[epoch:9, iter:902] Loss: 0.060 | Acc: 98.201% \n",
      "[epoch:9, iter:903] Loss: 0.060 | Acc: 98.168% \n",
      "[epoch:9, iter:904] Loss: 0.060 | Acc: 98.153% \n",
      "[epoch:9, iter:905] Loss: 0.061 | Acc: 98.139% \n",
      "[epoch:9, iter:906] Loss: 0.061 | Acc: 98.108% \n",
      "[epoch:9, iter:907] Loss: 0.063 | Acc: 98.077% \n",
      "[epoch:9, iter:908] Loss: 0.063 | Acc: 98.047% \n",
      "[epoch:9, iter:909] Loss: 0.063 | Acc: 98.068% \n",
      "[epoch:9, iter:910] Loss: 0.063 | Acc: 98.039% \n",
      "[epoch:9, iter:911] Loss: 0.064 | Acc: 98.026% \n",
      "[epoch:9, iter:912] Loss: 0.066 | Acc: 97.982% \n",
      "[epoch:9, iter:913] Loss: 0.066 | Acc: 97.970% \n",
      "[epoch:9, iter:914] Loss: 0.066 | Acc: 97.959% \n",
      "[epoch:9, iter:915] Loss: 0.065 | Acc: 97.964% \n",
      "[epoch:9, iter:916] Loss: 0.066 | Acc: 97.938% \n",
      "[epoch:9, iter:917] Loss: 0.065 | Acc: 97.942% \n",
      "[epoch:9, iter:918] Loss: 0.066 | Acc: 97.930% \n",
      "Waiting Val...\n",
      "Val's ac is: 0.000%\n",
      "save epoch 8 model\n",
      "\n",
      "Epoch: 10\n",
      "[epoch:10, iter:919] Loss: 0.010 | Acc: 100.000% \n",
      "[epoch:10, iter:920] Loss: 0.009 | Acc: 100.000% \n",
      "[epoch:10, iter:921] Loss: 0.048 | Acc: 97.917% \n",
      "[epoch:10, iter:922] Loss: 0.053 | Acc: 98.047% \n",
      "[epoch:10, iter:923] Loss: 0.060 | Acc: 97.500% \n",
      "[epoch:10, iter:924] Loss: 0.056 | Acc: 97.656% \n",
      "[epoch:10, iter:925] Loss: 0.051 | Acc: 97.768% \n",
      "[epoch:10, iter:926] Loss: 0.049 | Acc: 97.852% \n",
      "[epoch:10, iter:927] Loss: 0.048 | Acc: 97.917% \n",
      "[epoch:10, iter:928] Loss: 0.047 | Acc: 97.969% \n",
      "[epoch:10, iter:929] Loss: 0.044 | Acc: 98.011% \n",
      "[epoch:10, iter:930] Loss: 0.056 | Acc: 97.656% \n",
      "[epoch:10, iter:931] Loss: 0.056 | Acc: 97.716% \n",
      "[epoch:10, iter:932] Loss: 0.053 | Acc: 97.879% \n",
      "[epoch:10, iter:933] Loss: 0.051 | Acc: 97.917% \n",
      "[epoch:10, iter:934] Loss: 0.049 | Acc: 97.949% \n",
      "[epoch:10, iter:935] Loss: 0.047 | Acc: 97.978% \n",
      "[epoch:10, iter:936] Loss: 0.047 | Acc: 98.090% \n",
      "[epoch:10, iter:937] Loss: 0.045 | Acc: 98.191% \n",
      "[epoch:10, iter:938] Loss: 0.047 | Acc: 98.047% \n",
      "[epoch:10, iter:939] Loss: 0.047 | Acc: 98.065% \n",
      "[epoch:10, iter:940] Loss: 0.045 | Acc: 98.153% \n",
      "[epoch:10, iter:941] Loss: 0.044 | Acc: 98.098% \n",
      "[epoch:10, iter:942] Loss: 0.043 | Acc: 98.177% \n",
      "[epoch:10, iter:943] Loss: 0.042 | Acc: 98.250% \n",
      "[epoch:10, iter:944] Loss: 0.041 | Acc: 98.317% \n",
      "[epoch:10, iter:945] Loss: 0.040 | Acc: 98.380% \n",
      "[epoch:10, iter:946] Loss: 0.039 | Acc: 98.382% \n",
      "[epoch:10, iter:947] Loss: 0.039 | Acc: 98.438% \n",
      "[epoch:10, iter:948] Loss: 0.040 | Acc: 98.333% \n",
      "[epoch:10, iter:949] Loss: 0.042 | Acc: 98.286% \n",
      "[epoch:10, iter:950] Loss: 0.042 | Acc: 98.291% \n",
      "[epoch:10, iter:951] Loss: 0.044 | Acc: 98.248% \n",
      "[epoch:10, iter:952] Loss: 0.044 | Acc: 98.300% \n",
      "[epoch:10, iter:953] Loss: 0.044 | Acc: 98.304% \n",
      "[epoch:10, iter:954] Loss: 0.046 | Acc: 98.264% \n",
      "[epoch:10, iter:955] Loss: 0.045 | Acc: 98.311% \n",
      "[epoch:10, iter:956] Loss: 0.044 | Acc: 98.355% \n",
      "[epoch:10, iter:957] Loss: 0.043 | Acc: 98.397% \n",
      "[epoch:10, iter:958] Loss: 0.043 | Acc: 98.438% \n",
      "[epoch:10, iter:959] Loss: 0.042 | Acc: 98.476% \n",
      "[epoch:10, iter:960] Loss: 0.042 | Acc: 98.475% \n",
      "[epoch:10, iter:961] Loss: 0.041 | Acc: 98.510% \n",
      "[epoch:10, iter:962] Loss: 0.040 | Acc: 98.544% \n",
      "[epoch:10, iter:963] Loss: 0.040 | Acc: 98.576% \n",
      "[epoch:10, iter:964] Loss: 0.039 | Acc: 98.607% \n",
      "[epoch:10, iter:965] Loss: 0.041 | Acc: 98.570% \n",
      "[epoch:10, iter:966] Loss: 0.041 | Acc: 98.600% \n",
      "[epoch:10, iter:967] Loss: 0.043 | Acc: 98.533% \n",
      "[epoch:10, iter:968] Loss: 0.043 | Acc: 98.531% \n",
      "[epoch:10, iter:969] Loss: 0.042 | Acc: 98.560% \n",
      "[epoch:10, iter:970] Loss: 0.042 | Acc: 98.528% \n",
      "[epoch:10, iter:971] Loss: 0.042 | Acc: 98.555% \n",
      "[epoch:10, iter:972] Loss: 0.041 | Acc: 98.582% \n",
      "[epoch:10, iter:973] Loss: 0.042 | Acc: 98.523% \n",
      "[epoch:10, iter:974] Loss: 0.041 | Acc: 98.549% \n",
      "[epoch:10, iter:975] Loss: 0.041 | Acc: 98.575% \n",
      "[epoch:10, iter:976] Loss: 0.040 | Acc: 98.572% \n",
      "[epoch:10, iter:977] Loss: 0.040 | Acc: 98.596% \n",
      "[epoch:10, iter:978] Loss: 0.040 | Acc: 98.594% \n",
      "[epoch:10, iter:979] Loss: 0.040 | Acc: 98.591% \n",
      "[epoch:10, iter:980] Loss: 0.041 | Acc: 98.564% \n",
      "[epoch:10, iter:981] Loss: 0.041 | Acc: 98.586% \n",
      "[epoch:10, iter:982] Loss: 0.040 | Acc: 98.608% \n",
      "[epoch:10, iter:983] Loss: 0.040 | Acc: 98.606% \n",
      "[epoch:10, iter:984] Loss: 0.040 | Acc: 98.627% \n",
      "[epoch:10, iter:985] Loss: 0.040 | Acc: 98.624% \n",
      "[epoch:10, iter:986] Loss: 0.041 | Acc: 98.598% \n",
      "[epoch:10, iter:987] Loss: 0.040 | Acc: 98.619% \n",
      "[epoch:10, iter:988] Loss: 0.040 | Acc: 98.638% \n",
      "[epoch:10, iter:989] Loss: 0.040 | Acc: 98.658% \n",
      "[epoch:10, iter:990] Loss: 0.040 | Acc: 98.676% \n",
      "[epoch:10, iter:991] Loss: 0.039 | Acc: 98.694% \n",
      "[epoch:10, iter:992] Loss: 0.039 | Acc: 98.712% \n",
      "[epoch:10, iter:993] Loss: 0.039 | Acc: 98.708% \n",
      "[epoch:10, iter:994] Loss: 0.038 | Acc: 98.725% \n",
      "[epoch:10, iter:995] Loss: 0.038 | Acc: 98.722% \n",
      "[epoch:10, iter:996] Loss: 0.038 | Acc: 98.738% \n",
      "[epoch:10, iter:997] Loss: 0.038 | Acc: 98.734% \n",
      "[epoch:10, iter:998] Loss: 0.038 | Acc: 98.750% \n",
      "[epoch:10, iter:999] Loss: 0.037 | Acc: 98.765% \n",
      "[epoch:10, iter:1000] Loss: 0.037 | Acc: 98.761% \n",
      "[epoch:10, iter:1001] Loss: 0.037 | Acc: 98.758% \n",
      "[epoch:10, iter:1002] Loss: 0.038 | Acc: 98.717% \n",
      "[epoch:10, iter:1003] Loss: 0.037 | Acc: 98.732% \n",
      "[epoch:10, iter:1004] Loss: 0.037 | Acc: 98.746% \n",
      "[epoch:10, iter:1005] Loss: 0.037 | Acc: 98.761% \n",
      "[epoch:10, iter:1006] Loss: 0.037 | Acc: 98.722% \n",
      "[epoch:10, iter:1007] Loss: 0.038 | Acc: 98.718% \n",
      "[epoch:10, iter:1008] Loss: 0.038 | Acc: 98.715% \n",
      "[epoch:10, iter:1009] Loss: 0.038 | Acc: 98.712% \n",
      "[epoch:10, iter:1010] Loss: 0.040 | Acc: 98.709% \n",
      "[epoch:10, iter:1011] Loss: 0.039 | Acc: 98.723% \n",
      "[epoch:10, iter:1012] Loss: 0.039 | Acc: 98.737% \n",
      "[epoch:10, iter:1013] Loss: 0.039 | Acc: 98.734% \n",
      "[epoch:10, iter:1014] Loss: 0.039 | Acc: 98.714% \n",
      "[epoch:10, iter:1015] Loss: 0.039 | Acc: 98.727% \n",
      "[epoch:10, iter:1016] Loss: 0.039 | Acc: 98.724% \n",
      "[epoch:10, iter:1017] Loss: 0.038 | Acc: 98.737% \n",
      "[epoch:10, iter:1018] Loss: 0.038 | Acc: 98.750% \n",
      "[epoch:10, iter:1019] Loss: 0.038 | Acc: 98.747% \n",
      "[epoch:10, iter:1020] Loss: 0.038 | Acc: 98.727% \n",
      "Waiting Val...\n",
      "Val's ac is: 0.000%\n",
      "save epoch 9 model\n",
      "\n",
      "Epoch: 11\n",
      "[epoch:11, iter:1021] Loss: 0.003 | Acc: 100.000% \n",
      "[epoch:11, iter:1022] Loss: 0.019 | Acc: 99.219% \n",
      "[epoch:11, iter:1023] Loss: 0.014 | Acc: 99.479% \n",
      "[epoch:11, iter:1024] Loss: 0.015 | Acc: 99.609% \n",
      "[epoch:11, iter:1025] Loss: 0.013 | Acc: 99.688% \n",
      "[epoch:11, iter:1026] Loss: 0.013 | Acc: 99.740% \n",
      "[epoch:11, iter:1027] Loss: 0.021 | Acc: 99.554% \n",
      "[epoch:11, iter:1028] Loss: 0.022 | Acc: 99.414% \n",
      "[epoch:11, iter:1029] Loss: 0.021 | Acc: 99.479% \n",
      "[epoch:11, iter:1030] Loss: 0.023 | Acc: 99.375% \n",
      "[epoch:11, iter:1031] Loss: 0.023 | Acc: 99.290% \n",
      "[epoch:11, iter:1032] Loss: 0.025 | Acc: 99.219% \n",
      "[epoch:11, iter:1033] Loss: 0.025 | Acc: 99.159% \n",
      "[epoch:11, iter:1034] Loss: 0.023 | Acc: 99.219% \n",
      "[epoch:11, iter:1035] Loss: 0.024 | Acc: 99.167% \n",
      "[epoch:11, iter:1036] Loss: 0.023 | Acc: 99.219% \n",
      "[epoch:11, iter:1037] Loss: 0.025 | Acc: 99.173% \n",
      "[epoch:11, iter:1038] Loss: 0.024 | Acc: 99.219% \n",
      "[epoch:11, iter:1039] Loss: 0.023 | Acc: 99.260% \n",
      "[epoch:11, iter:1040] Loss: 0.023 | Acc: 99.297% \n",
      "[epoch:11, iter:1041] Loss: 0.022 | Acc: 99.330% \n",
      "[epoch:11, iter:1042] Loss: 0.021 | Acc: 99.361% \n",
      "[epoch:11, iter:1043] Loss: 0.021 | Acc: 99.389% \n",
      "[epoch:11, iter:1044] Loss: 0.021 | Acc: 99.349% \n",
      "[epoch:11, iter:1045] Loss: 0.021 | Acc: 99.375% \n",
      "[epoch:11, iter:1046] Loss: 0.020 | Acc: 99.399% \n",
      "[epoch:11, iter:1047] Loss: 0.021 | Acc: 99.363% \n",
      "[epoch:11, iter:1048] Loss: 0.020 | Acc: 99.386% \n",
      "[epoch:11, iter:1049] Loss: 0.020 | Acc: 99.353% \n",
      "[epoch:11, iter:1050] Loss: 0.020 | Acc: 99.375% \n",
      "[epoch:11, iter:1051] Loss: 0.019 | Acc: 99.395% \n",
      "[epoch:11, iter:1052] Loss: 0.019 | Acc: 99.365% \n",
      "[epoch:11, iter:1053] Loss: 0.019 | Acc: 99.384% \n",
      "[epoch:11, iter:1054] Loss: 0.021 | Acc: 99.357% \n",
      "[epoch:11, iter:1055] Loss: 0.023 | Acc: 99.330% \n",
      "[epoch:11, iter:1056] Loss: 0.023 | Acc: 99.349% \n",
      "[epoch:11, iter:1057] Loss: 0.022 | Acc: 99.367% \n",
      "[epoch:11, iter:1058] Loss: 0.022 | Acc: 99.383% \n",
      "[epoch:11, iter:1059] Loss: 0.021 | Acc: 99.399% \n",
      "[epoch:11, iter:1060] Loss: 0.021 | Acc: 99.375% \n",
      "[epoch:11, iter:1061] Loss: 0.021 | Acc: 99.390% \n",
      "[epoch:11, iter:1062] Loss: 0.023 | Acc: 99.256% \n",
      "[epoch:11, iter:1063] Loss: 0.022 | Acc: 99.273% \n",
      "[epoch:11, iter:1064] Loss: 0.023 | Acc: 99.254% \n",
      "[epoch:11, iter:1065] Loss: 0.023 | Acc: 99.236% \n",
      "[epoch:11, iter:1066] Loss: 0.023 | Acc: 99.219% \n",
      "[epoch:11, iter:1067] Loss: 0.023 | Acc: 99.235% \n",
      "[epoch:11, iter:1068] Loss: 0.024 | Acc: 99.186% \n",
      "[epoch:11, iter:1069] Loss: 0.024 | Acc: 99.203% \n",
      "[epoch:11, iter:1070] Loss: 0.023 | Acc: 99.219% \n",
      "[epoch:11, iter:1071] Loss: 0.024 | Acc: 99.203% \n",
      "[epoch:11, iter:1072] Loss: 0.024 | Acc: 99.219% \n",
      "[epoch:11, iter:1073] Loss: 0.023 | Acc: 99.233% \n",
      "[epoch:11, iter:1074] Loss: 0.023 | Acc: 99.248% \n",
      "[epoch:11, iter:1075] Loss: 0.023 | Acc: 99.261% \n",
      "[epoch:11, iter:1076] Loss: 0.023 | Acc: 99.275% \n",
      "[epoch:11, iter:1077] Loss: 0.023 | Acc: 99.287% \n",
      "[epoch:11, iter:1078] Loss: 0.022 | Acc: 99.300% \n",
      "[epoch:11, iter:1079] Loss: 0.023 | Acc: 99.285% \n",
      "[epoch:11, iter:1080] Loss: 0.022 | Acc: 99.297% \n",
      "[epoch:11, iter:1081] Loss: 0.022 | Acc: 99.308% \n",
      "[epoch:11, iter:1082] Loss: 0.023 | Acc: 99.244% \n",
      "[epoch:11, iter:1083] Loss: 0.023 | Acc: 99.256% \n",
      "[epoch:11, iter:1084] Loss: 0.023 | Acc: 99.268% \n",
      "[epoch:11, iter:1085] Loss: 0.025 | Acc: 99.231% \n",
      "[epoch:11, iter:1086] Loss: 0.024 | Acc: 99.242% \n",
      "[epoch:11, iter:1087] Loss: 0.025 | Acc: 99.230% \n",
      "[epoch:11, iter:1088] Loss: 0.024 | Acc: 99.242% \n",
      "[epoch:11, iter:1089] Loss: 0.024 | Acc: 99.253% \n",
      "[epoch:11, iter:1090] Loss: 0.024 | Acc: 99.263% \n",
      "[epoch:11, iter:1091] Loss: 0.024 | Acc: 99.252% \n",
      "[epoch:11, iter:1092] Loss: 0.024 | Acc: 99.262% \n",
      "[epoch:11, iter:1093] Loss: 0.024 | Acc: 99.272% \n",
      "[epoch:11, iter:1094] Loss: 0.025 | Acc: 99.240% \n",
      "[epoch:11, iter:1095] Loss: 0.025 | Acc: 99.229% \n",
      "[epoch:11, iter:1096] Loss: 0.026 | Acc: 99.198% \n",
      "[epoch:11, iter:1097] Loss: 0.026 | Acc: 99.188% \n",
      "[epoch:11, iter:1098] Loss: 0.026 | Acc: 99.179% \n",
      "[epoch:11, iter:1099] Loss: 0.026 | Acc: 99.189% \n",
      "[epoch:11, iter:1100] Loss: 0.027 | Acc: 99.180% \n",
      "[epoch:11, iter:1101] Loss: 0.027 | Acc: 99.171% \n",
      "[epoch:11, iter:1102] Loss: 0.027 | Acc: 99.181% \n",
      "[epoch:11, iter:1103] Loss: 0.027 | Acc: 99.191% \n",
      "[epoch:11, iter:1104] Loss: 0.027 | Acc: 99.200% \n",
      "[epoch:11, iter:1105] Loss: 0.027 | Acc: 99.191% \n",
      "[epoch:11, iter:1106] Loss: 0.027 | Acc: 99.201% \n",
      "[epoch:11, iter:1107] Loss: 0.028 | Acc: 99.174% \n",
      "[epoch:11, iter:1108] Loss: 0.029 | Acc: 99.112% \n",
      "[epoch:11, iter:1109] Loss: 0.029 | Acc: 99.122% \n",
      "[epoch:11, iter:1110] Loss: 0.029 | Acc: 99.132% \n",
      "[epoch:11, iter:1111] Loss: 0.030 | Acc: 99.090% \n",
      "[epoch:11, iter:1112] Loss: 0.030 | Acc: 99.100% \n",
      "[epoch:11, iter:1113] Loss: 0.031 | Acc: 99.093% \n",
      "[epoch:11, iter:1114] Loss: 0.031 | Acc: 99.086% \n",
      "[epoch:11, iter:1115] Loss: 0.031 | Acc: 99.079% \n",
      "[epoch:11, iter:1116] Loss: 0.031 | Acc: 99.072% \n",
      "[epoch:11, iter:1117] Loss: 0.031 | Acc: 99.082% \n",
      "[epoch:11, iter:1118] Loss: 0.031 | Acc: 99.075% \n",
      "[epoch:11, iter:1119] Loss: 0.031 | Acc: 99.069% \n",
      "[epoch:11, iter:1120] Loss: 0.031 | Acc: 99.047% \n",
      "[epoch:11, iter:1121] Loss: 0.032 | Acc: 99.010% \n",
      "[epoch:11, iter:1122] Loss: 0.031 | Acc: 99.019% \n",
      "Waiting Val...\n",
      "Val's ac is: 0.000%\n",
      "save epoch 10 model\n",
      "\n",
      "Epoch: 12\n",
      "[epoch:12, iter:1123] Loss: 0.009 | Acc: 100.000% \n",
      "[epoch:12, iter:1124] Loss: 0.022 | Acc: 98.438% \n",
      "[epoch:12, iter:1125] Loss: 0.033 | Acc: 97.917% \n",
      "[epoch:12, iter:1126] Loss: 0.026 | Acc: 98.438% \n",
      "[epoch:12, iter:1127] Loss: 0.022 | Acc: 98.750% \n",
      "[epoch:12, iter:1128] Loss: 0.035 | Acc: 98.438% \n",
      "[epoch:12, iter:1129] Loss: 0.030 | Acc: 98.661% \n",
      "[epoch:12, iter:1130] Loss: 0.028 | Acc: 98.828% \n",
      "[epoch:12, iter:1131] Loss: 0.027 | Acc: 98.958% \n",
      "[epoch:12, iter:1132] Loss: 0.033 | Acc: 98.750% \n",
      "[epoch:12, iter:1133] Loss: 0.033 | Acc: 98.722% \n",
      "[epoch:12, iter:1134] Loss: 0.043 | Acc: 98.568% \n",
      "[epoch:12, iter:1135] Loss: 0.040 | Acc: 98.678% \n",
      "[epoch:12, iter:1136] Loss: 0.038 | Acc: 98.772% \n",
      "[epoch:12, iter:1137] Loss: 0.036 | Acc: 98.854% \n",
      "[epoch:12, iter:1138] Loss: 0.035 | Acc: 98.926% \n",
      "[epoch:12, iter:1139] Loss: 0.034 | Acc: 98.989% \n",
      "[epoch:12, iter:1140] Loss: 0.032 | Acc: 99.045% \n",
      "[epoch:12, iter:1141] Loss: 0.032 | Acc: 99.095% \n",
      "[epoch:12, iter:1142] Loss: 0.031 | Acc: 99.141% \n",
      "[epoch:12, iter:1143] Loss: 0.030 | Acc: 99.182% \n",
      "[epoch:12, iter:1144] Loss: 0.030 | Acc: 99.148% \n",
      "[epoch:12, iter:1145] Loss: 0.029 | Acc: 99.185% \n",
      "[epoch:12, iter:1146] Loss: 0.028 | Acc: 99.219% \n",
      "[epoch:12, iter:1147] Loss: 0.027 | Acc: 99.250% \n",
      "[epoch:12, iter:1148] Loss: 0.027 | Acc: 99.279% \n",
      "[epoch:12, iter:1149] Loss: 0.029 | Acc: 99.190% \n",
      "[epoch:12, iter:1150] Loss: 0.028 | Acc: 99.219% \n",
      "[epoch:12, iter:1151] Loss: 0.027 | Acc: 99.246% \n",
      "[epoch:12, iter:1152] Loss: 0.027 | Acc: 99.219% \n",
      "[epoch:12, iter:1153] Loss: 0.026 | Acc: 99.244% \n",
      "[epoch:12, iter:1154] Loss: 0.027 | Acc: 99.219% \n",
      "[epoch:12, iter:1155] Loss: 0.027 | Acc: 99.148% \n",
      "[epoch:12, iter:1156] Loss: 0.028 | Acc: 99.173% \n",
      "[epoch:12, iter:1157] Loss: 0.027 | Acc: 99.196% \n",
      "[epoch:12, iter:1158] Loss: 0.029 | Acc: 99.175% \n",
      "[epoch:12, iter:1159] Loss: 0.032 | Acc: 99.071% \n",
      "[epoch:12, iter:1160] Loss: 0.031 | Acc: 99.095% \n",
      "[epoch:12, iter:1161] Loss: 0.032 | Acc: 99.079% \n",
      "[epoch:12, iter:1162] Loss: 0.034 | Acc: 98.984% \n",
      "[epoch:12, iter:1163] Loss: 0.034 | Acc: 98.971% \n",
      "[epoch:12, iter:1164] Loss: 0.033 | Acc: 98.996% \n",
      "[epoch:12, iter:1165] Loss: 0.033 | Acc: 99.019% \n",
      "[epoch:12, iter:1166] Loss: 0.032 | Acc: 99.041% \n",
      "[epoch:12, iter:1167] Loss: 0.033 | Acc: 99.028% \n",
      "[epoch:12, iter:1168] Loss: 0.033 | Acc: 99.015% \n",
      "[epoch:12, iter:1169] Loss: 0.033 | Acc: 99.003% \n",
      "[epoch:12, iter:1170] Loss: 0.033 | Acc: 99.023% \n",
      "[epoch:12, iter:1171] Loss: 0.032 | Acc: 99.043% \n",
      "[epoch:12, iter:1172] Loss: 0.032 | Acc: 99.062% \n",
      "[epoch:12, iter:1173] Loss: 0.032 | Acc: 99.081% \n",
      "[epoch:12, iter:1174] Loss: 0.031 | Acc: 99.099% \n",
      "[epoch:12, iter:1175] Loss: 0.031 | Acc: 99.116% \n",
      "[epoch:12, iter:1176] Loss: 0.031 | Acc: 99.074% \n",
      "[epoch:12, iter:1177] Loss: 0.031 | Acc: 99.091% \n",
      "[epoch:12, iter:1178] Loss: 0.031 | Acc: 99.107% \n",
      "[epoch:12, iter:1179] Loss: 0.030 | Acc: 99.123% \n",
      "[epoch:12, iter:1180] Loss: 0.031 | Acc: 99.111% \n",
      "[epoch:12, iter:1181] Loss: 0.030 | Acc: 99.126% \n",
      "[epoch:12, iter:1182] Loss: 0.030 | Acc: 99.141% \n",
      "[epoch:12, iter:1183] Loss: 0.030 | Acc: 99.155% \n",
      "[epoch:12, iter:1184] Loss: 0.029 | Acc: 99.168% \n",
      "[epoch:12, iter:1185] Loss: 0.029 | Acc: 99.182% \n",
      "[epoch:12, iter:1186] Loss: 0.028 | Acc: 99.194% \n",
      "[epoch:12, iter:1187] Loss: 0.028 | Acc: 99.207% \n",
      "[epoch:12, iter:1188] Loss: 0.028 | Acc: 99.219% \n",
      "[epoch:12, iter:1189] Loss: 0.027 | Acc: 99.230% \n",
      "[epoch:12, iter:1190] Loss: 0.028 | Acc: 99.196% \n",
      "[epoch:12, iter:1191] Loss: 0.028 | Acc: 99.207% \n",
      "[epoch:12, iter:1192] Loss: 0.028 | Acc: 99.219% \n",
      "[epoch:12, iter:1193] Loss: 0.027 | Acc: 99.230% \n",
      "[epoch:12, iter:1194] Loss: 0.028 | Acc: 99.219% \n",
      "[epoch:12, iter:1195] Loss: 0.028 | Acc: 99.187% \n",
      "[epoch:12, iter:1196] Loss: 0.028 | Acc: 99.177% \n",
      "[epoch:12, iter:1197] Loss: 0.028 | Acc: 99.188% \n",
      "[epoch:12, iter:1198] Loss: 0.028 | Acc: 99.198% \n",
      "[epoch:12, iter:1199] Loss: 0.029 | Acc: 99.148% \n",
      "[epoch:12, iter:1200] Loss: 0.029 | Acc: 99.139% \n",
      "[epoch:12, iter:1201] Loss: 0.029 | Acc: 99.130% \n",
      "[epoch:12, iter:1202] Loss: 0.030 | Acc: 99.121% \n",
      "[epoch:12, iter:1203] Loss: 0.029 | Acc: 99.113% \n",
      "[epoch:12, iter:1204] Loss: 0.030 | Acc: 99.085% \n",
      "[epoch:12, iter:1205] Loss: 0.029 | Acc: 99.096% \n",
      "[epoch:12, iter:1206] Loss: 0.030 | Acc: 99.089% \n",
      "[epoch:12, iter:1207] Loss: 0.030 | Acc: 99.099% \n",
      "[epoch:12, iter:1208] Loss: 0.031 | Acc: 99.073% \n",
      "[epoch:12, iter:1209] Loss: 0.031 | Acc: 99.084% \n",
      "[epoch:12, iter:1210] Loss: 0.030 | Acc: 99.094% \n",
      "[epoch:12, iter:1211] Loss: 0.031 | Acc: 99.070% \n",
      "[epoch:12, iter:1212] Loss: 0.031 | Acc: 99.062% \n",
      "[epoch:12, iter:1213] Loss: 0.031 | Acc: 99.073% \n",
      "[epoch:12, iter:1214] Loss: 0.031 | Acc: 99.083% \n",
      "[epoch:12, iter:1215] Loss: 0.030 | Acc: 99.093% \n",
      "[epoch:12, iter:1216] Loss: 0.031 | Acc: 99.086% \n",
      "[epoch:12, iter:1217] Loss: 0.030 | Acc: 99.095% \n",
      "[epoch:12, iter:1218] Loss: 0.030 | Acc: 99.105% \n",
      "[epoch:12, iter:1219] Loss: 0.030 | Acc: 99.098% \n",
      "[epoch:12, iter:1220] Loss: 0.030 | Acc: 99.091% \n",
      "[epoch:12, iter:1221] Loss: 0.030 | Acc: 99.085% \n",
      "[epoch:12, iter:1222] Loss: 0.030 | Acc: 99.078% \n",
      "[epoch:12, iter:1223] Loss: 0.030 | Acc: 99.056% \n",
      "[epoch:12, iter:1224] Loss: 0.030 | Acc: 99.065% \n",
      "Waiting Val...\n",
      "Val's ac is: 0.000%\n",
      "save epoch 11 model\n",
      "\n",
      "Epoch: 13\n",
      "[epoch:13, iter:1225] Loss: 0.012 | Acc: 100.000% \n",
      "[epoch:13, iter:1226] Loss: 0.016 | Acc: 100.000% \n",
      "[epoch:13, iter:1227] Loss: 0.019 | Acc: 99.479% \n",
      "[epoch:13, iter:1228] Loss: 0.015 | Acc: 99.609% \n",
      "[epoch:13, iter:1229] Loss: 0.015 | Acc: 99.688% \n",
      "[epoch:13, iter:1230] Loss: 0.016 | Acc: 99.479% \n",
      "[epoch:13, iter:1231] Loss: 0.015 | Acc: 99.554% \n",
      "[epoch:13, iter:1232] Loss: 0.014 | Acc: 99.609% \n",
      "[epoch:13, iter:1233] Loss: 0.013 | Acc: 99.653% \n",
      "[epoch:13, iter:1234] Loss: 0.013 | Acc: 99.688% \n",
      "[epoch:13, iter:1235] Loss: 0.012 | Acc: 99.716% \n",
      "[epoch:13, iter:1236] Loss: 0.011 | Acc: 99.740% \n",
      "[epoch:13, iter:1237] Loss: 0.013 | Acc: 99.639% \n",
      "[epoch:13, iter:1238] Loss: 0.014 | Acc: 99.554% \n",
      "[epoch:13, iter:1239] Loss: 0.015 | Acc: 99.479% \n",
      "[epoch:13, iter:1240] Loss: 0.015 | Acc: 99.512% \n",
      "[epoch:13, iter:1241] Loss: 0.015 | Acc: 99.540% \n",
      "[epoch:13, iter:1242] Loss: 0.019 | Acc: 99.479% \n",
      "[epoch:13, iter:1243] Loss: 0.018 | Acc: 99.507% \n",
      "[epoch:13, iter:1244] Loss: 0.017 | Acc: 99.531% \n",
      "[epoch:13, iter:1245] Loss: 0.019 | Acc: 99.479% \n",
      "[epoch:13, iter:1246] Loss: 0.018 | Acc: 99.503% \n",
      "[epoch:13, iter:1247] Loss: 0.018 | Acc: 99.524% \n",
      "[epoch:13, iter:1248] Loss: 0.018 | Acc: 99.479% \n",
      "[epoch:13, iter:1249] Loss: 0.018 | Acc: 99.500% \n",
      "[epoch:13, iter:1250] Loss: 0.018 | Acc: 99.459% \n",
      "[epoch:13, iter:1251] Loss: 0.017 | Acc: 99.479% \n",
      "[epoch:13, iter:1252] Loss: 0.017 | Acc: 99.498% \n",
      "[epoch:13, iter:1253] Loss: 0.018 | Acc: 99.461% \n",
      "[epoch:13, iter:1254] Loss: 0.018 | Acc: 99.479% \n",
      "[epoch:13, iter:1255] Loss: 0.017 | Acc: 99.496% \n",
      "[epoch:13, iter:1256] Loss: 0.017 | Acc: 99.512% \n",
      "[epoch:13, iter:1257] Loss: 0.017 | Acc: 99.527% \n",
      "[epoch:13, iter:1258] Loss: 0.016 | Acc: 99.540% \n",
      "[epoch:13, iter:1259] Loss: 0.016 | Acc: 99.554% \n",
      "[epoch:13, iter:1260] Loss: 0.016 | Acc: 99.566% \n",
      "[epoch:13, iter:1261] Loss: 0.019 | Acc: 99.493% \n",
      "[epoch:13, iter:1262] Loss: 0.019 | Acc: 99.507% \n",
      "[epoch:13, iter:1263] Loss: 0.019 | Acc: 99.519% \n",
      "[epoch:13, iter:1264] Loss: 0.020 | Acc: 99.492% \n",
      "[epoch:13, iter:1265] Loss: 0.020 | Acc: 99.505% \n",
      "[epoch:13, iter:1266] Loss: 0.020 | Acc: 99.516% \n",
      "[epoch:13, iter:1267] Loss: 0.019 | Acc: 99.528% \n",
      "[epoch:13, iter:1268] Loss: 0.021 | Acc: 99.503% \n",
      "[epoch:13, iter:1269] Loss: 0.021 | Acc: 99.514% \n",
      "[epoch:13, iter:1270] Loss: 0.021 | Acc: 99.490% \n",
      "[epoch:13, iter:1271] Loss: 0.021 | Acc: 99.501% \n",
      "[epoch:13, iter:1272] Loss: 0.021 | Acc: 99.512% \n",
      "[epoch:13, iter:1273] Loss: 0.021 | Acc: 99.522% \n",
      "[epoch:13, iter:1274] Loss: 0.021 | Acc: 99.531% \n",
      "[epoch:13, iter:1275] Loss: 0.021 | Acc: 99.510% \n",
      "[epoch:13, iter:1276] Loss: 0.021 | Acc: 99.519% \n",
      "[epoch:13, iter:1277] Loss: 0.021 | Acc: 99.528% \n",
      "[epoch:13, iter:1278] Loss: 0.021 | Acc: 99.537% \n",
      "[epoch:13, iter:1279] Loss: 0.021 | Acc: 99.545% \n",
      "[epoch:13, iter:1280] Loss: 0.021 | Acc: 99.526% \n",
      "[epoch:13, iter:1281] Loss: 0.020 | Acc: 99.534% \n",
      "[epoch:13, iter:1282] Loss: 0.020 | Acc: 99.542% \n",
      "[epoch:13, iter:1283] Loss: 0.020 | Acc: 99.550% \n",
      "[epoch:13, iter:1284] Loss: 0.020 | Acc: 99.531% \n",
      "[epoch:13, iter:1285] Loss: 0.020 | Acc: 99.539% \n",
      "[epoch:13, iter:1286] Loss: 0.021 | Acc: 99.521% \n",
      "[epoch:13, iter:1287] Loss: 0.021 | Acc: 99.504% \n",
      "[epoch:13, iter:1288] Loss: 0.021 | Acc: 99.487% \n",
      "[epoch:13, iter:1289] Loss: 0.021 | Acc: 99.495% \n",
      "[epoch:13, iter:1290] Loss: 0.021 | Acc: 99.479% \n",
      "[epoch:13, iter:1291] Loss: 0.021 | Acc: 99.487% \n",
      "[epoch:13, iter:1292] Loss: 0.021 | Acc: 99.494% \n",
      "[epoch:13, iter:1293] Loss: 0.022 | Acc: 99.434% \n",
      "[epoch:13, iter:1294] Loss: 0.023 | Acc: 99.397% \n",
      "[epoch:13, iter:1295] Loss: 0.024 | Acc: 99.362% \n",
      "[epoch:13, iter:1296] Loss: 0.023 | Acc: 99.371% \n",
      "[epoch:13, iter:1297] Loss: 0.024 | Acc: 99.358% \n",
      "[epoch:13, iter:1298] Loss: 0.024 | Acc: 99.345% \n",
      "[epoch:13, iter:1299] Loss: 0.025 | Acc: 99.312% \n",
      "[epoch:13, iter:1300] Loss: 0.025 | Acc: 99.301% \n",
      "[epoch:13, iter:1301] Loss: 0.025 | Acc: 99.290% \n",
      "[epoch:13, iter:1302] Loss: 0.025 | Acc: 99.279% \n",
      "[epoch:13, iter:1303] Loss: 0.025 | Acc: 99.268% \n",
      "[epoch:13, iter:1304] Loss: 0.025 | Acc: 99.277% \n",
      "[epoch:13, iter:1305] Loss: 0.025 | Acc: 99.286% \n",
      "[epoch:13, iter:1306] Loss: 0.025 | Acc: 99.295% \n",
      "[epoch:13, iter:1307] Loss: 0.024 | Acc: 99.303% \n",
      "[epoch:13, iter:1308] Loss: 0.024 | Acc: 99.312% \n",
      "[epoch:13, iter:1309] Loss: 0.024 | Acc: 99.320% \n",
      "[epoch:13, iter:1310] Loss: 0.024 | Acc: 99.310% \n",
      "[epoch:13, iter:1311] Loss: 0.024 | Acc: 99.300% \n",
      "[epoch:13, iter:1312] Loss: 0.024 | Acc: 99.308% \n",
      "[epoch:13, iter:1313] Loss: 0.024 | Acc: 99.298% \n",
      "[epoch:13, iter:1314] Loss: 0.024 | Acc: 99.306% \n",
      "[epoch:13, iter:1315] Loss: 0.024 | Acc: 99.313% \n",
      "[epoch:13, iter:1316] Loss: 0.024 | Acc: 99.287% \n",
      "[epoch:13, iter:1317] Loss: 0.024 | Acc: 99.294% \n",
      "[epoch:13, iter:1318] Loss: 0.024 | Acc: 99.285% \n",
      "[epoch:13, iter:1319] Loss: 0.023 | Acc: 99.293% \n",
      "[epoch:13, iter:1320] Loss: 0.023 | Acc: 99.300% \n",
      "[epoch:13, iter:1321] Loss: 0.024 | Acc: 99.291% \n",
      "[epoch:13, iter:1322] Loss: 0.023 | Acc: 99.298% \n",
      "[epoch:13, iter:1323] Loss: 0.023 | Acc: 99.290% \n",
      "[epoch:13, iter:1324] Loss: 0.023 | Acc: 99.297% \n",
      "[epoch:13, iter:1325] Loss: 0.024 | Acc: 99.273% \n",
      "[epoch:13, iter:1326] Loss: 0.024 | Acc: 99.279% \n",
      "Waiting Val...\n",
      "Val's ac is: 0.000%\n",
      "save epoch 12 model\n",
      "\n",
      "Epoch: 14\n",
      "[epoch:14, iter:1327] Loss: 0.008 | Acc: 100.000% \n",
      "[epoch:14, iter:1328] Loss: 0.057 | Acc: 99.219% \n",
      "[epoch:14, iter:1329] Loss: 0.045 | Acc: 99.479% \n",
      "[epoch:14, iter:1330] Loss: 0.034 | Acc: 99.609% \n",
      "[epoch:14, iter:1331] Loss: 0.028 | Acc: 99.688% \n",
      "[epoch:14, iter:1332] Loss: 0.027 | Acc: 99.740% \n",
      "[epoch:14, iter:1333] Loss: 0.031 | Acc: 99.330% \n",
      "[epoch:14, iter:1334] Loss: 0.027 | Acc: 99.414% \n",
      "[epoch:14, iter:1335] Loss: 0.025 | Acc: 99.479% \n",
      "[epoch:14, iter:1336] Loss: 0.024 | Acc: 99.531% \n",
      "[epoch:14, iter:1337] Loss: 0.022 | Acc: 99.574% \n",
      "[epoch:14, iter:1338] Loss: 0.023 | Acc: 99.479% \n",
      "[epoch:14, iter:1339] Loss: 0.022 | Acc: 99.519% \n",
      "[epoch:14, iter:1340] Loss: 0.021 | Acc: 99.554% \n",
      "[epoch:14, iter:1341] Loss: 0.020 | Acc: 99.583% \n",
      "[epoch:14, iter:1342] Loss: 0.020 | Acc: 99.609% \n",
      "[epoch:14, iter:1343] Loss: 0.021 | Acc: 99.540% \n",
      "[epoch:14, iter:1344] Loss: 0.020 | Acc: 99.566% \n",
      "[epoch:14, iter:1345] Loss: 0.019 | Acc: 99.589% \n",
      "[epoch:14, iter:1346] Loss: 0.018 | Acc: 99.609% \n",
      "[epoch:14, iter:1347] Loss: 0.020 | Acc: 99.554% \n",
      "[epoch:14, iter:1348] Loss: 0.019 | Acc: 99.574% \n",
      "[epoch:14, iter:1349] Loss: 0.019 | Acc: 99.524% \n",
      "[epoch:14, iter:1350] Loss: 0.020 | Acc: 99.479% \n",
      "[epoch:14, iter:1351] Loss: 0.019 | Acc: 99.500% \n",
      "[epoch:14, iter:1352] Loss: 0.019 | Acc: 99.519% \n",
      "[epoch:14, iter:1353] Loss: 0.018 | Acc: 99.537% \n",
      "[epoch:14, iter:1354] Loss: 0.018 | Acc: 99.498% \n",
      "[epoch:14, iter:1355] Loss: 0.018 | Acc: 99.515% \n",
      "[epoch:14, iter:1356] Loss: 0.017 | Acc: 99.531% \n",
      "[epoch:14, iter:1357] Loss: 0.017 | Acc: 99.546% \n",
      "[epoch:14, iter:1358] Loss: 0.017 | Acc: 99.561% \n",
      "[epoch:14, iter:1359] Loss: 0.016 | Acc: 99.574% \n",
      "[epoch:14, iter:1360] Loss: 0.016 | Acc: 99.586% \n",
      "[epoch:14, iter:1361] Loss: 0.016 | Acc: 99.598% \n",
      "[epoch:14, iter:1362] Loss: 0.016 | Acc: 99.609% \n",
      "[epoch:14, iter:1363] Loss: 0.015 | Acc: 99.620% \n",
      "[epoch:14, iter:1364] Loss: 0.016 | Acc: 99.589% \n",
      "[epoch:14, iter:1365] Loss: 0.016 | Acc: 99.599% \n",
      "[epoch:14, iter:1366] Loss: 0.016 | Acc: 99.609% \n",
      "[epoch:14, iter:1367] Loss: 0.016 | Acc: 99.619% \n",
      "[epoch:14, iter:1368] Loss: 0.016 | Acc: 99.628% \n",
      "[epoch:14, iter:1369] Loss: 0.016 | Acc: 99.600% \n",
      "[epoch:14, iter:1370] Loss: 0.016 | Acc: 99.574% \n",
      "[epoch:14, iter:1371] Loss: 0.016 | Acc: 99.583% \n",
      "[epoch:14, iter:1372] Loss: 0.016 | Acc: 99.592% \n",
      "[epoch:14, iter:1373] Loss: 0.016 | Acc: 99.568% \n",
      "[epoch:14, iter:1374] Loss: 0.016 | Acc: 99.544% \n",
      "[epoch:14, iter:1375] Loss: 0.016 | Acc: 99.554% \n",
      "[epoch:14, iter:1376] Loss: 0.016 | Acc: 99.531% \n",
      "[epoch:14, iter:1377] Loss: 0.016 | Acc: 99.540% \n",
      "[epoch:14, iter:1378] Loss: 0.016 | Acc: 99.549% \n",
      "[epoch:14, iter:1379] Loss: 0.016 | Acc: 99.558% \n",
      "[epoch:14, iter:1380] Loss: 0.016 | Acc: 99.566% \n",
      "[epoch:14, iter:1381] Loss: 0.015 | Acc: 99.574% \n",
      "[epoch:14, iter:1382] Loss: 0.015 | Acc: 99.581% \n",
      "[epoch:14, iter:1383] Loss: 0.015 | Acc: 99.589% \n",
      "[epoch:14, iter:1384] Loss: 0.015 | Acc: 99.596% \n",
      "[epoch:14, iter:1385] Loss: 0.015 | Acc: 99.603% \n",
      "[epoch:14, iter:1386] Loss: 0.015 | Acc: 99.583% \n",
      "[epoch:14, iter:1387] Loss: 0.016 | Acc: 99.565% \n",
      "[epoch:14, iter:1388] Loss: 0.016 | Acc: 99.572% \n",
      "[epoch:14, iter:1389] Loss: 0.016 | Acc: 99.554% \n",
      "[epoch:14, iter:1390] Loss: 0.017 | Acc: 99.536% \n",
      "[epoch:14, iter:1391] Loss: 0.017 | Acc: 99.543% \n",
      "[epoch:14, iter:1392] Loss: 0.017 | Acc: 99.550% \n",
      "[epoch:14, iter:1393] Loss: 0.017 | Acc: 99.534% \n",
      "[epoch:14, iter:1394] Loss: 0.018 | Acc: 99.517% \n",
      "[epoch:14, iter:1395] Loss: 0.018 | Acc: 99.502% \n",
      "[epoch:14, iter:1396] Loss: 0.018 | Acc: 99.509% \n",
      "[epoch:14, iter:1397] Loss: 0.018 | Acc: 99.516% \n",
      "[epoch:14, iter:1398] Loss: 0.017 | Acc: 99.523% \n",
      "[epoch:14, iter:1399] Loss: 0.017 | Acc: 99.529% \n",
      "[epoch:14, iter:1400] Loss: 0.017 | Acc: 99.535% \n",
      "[epoch:14, iter:1401] Loss: 0.017 | Acc: 99.542% \n",
      "[epoch:14, iter:1402] Loss: 0.018 | Acc: 99.486% \n",
      "[epoch:14, iter:1403] Loss: 0.018 | Acc: 99.493% \n",
      "[epoch:14, iter:1404] Loss: 0.018 | Acc: 99.499% \n",
      "[epoch:14, iter:1405] Loss: 0.018 | Acc: 99.506% \n",
      "[epoch:14, iter:1406] Loss: 0.018 | Acc: 99.492% \n",
      "[epoch:14, iter:1407] Loss: 0.018 | Acc: 99.498% \n",
      "[epoch:14, iter:1408] Loss: 0.018 | Acc: 99.505% \n",
      "[epoch:14, iter:1409] Loss: 0.017 | Acc: 99.511% \n",
      "[epoch:14, iter:1410] Loss: 0.018 | Acc: 99.498% \n",
      "[epoch:14, iter:1411] Loss: 0.018 | Acc: 99.485% \n",
      "[epoch:14, iter:1412] Loss: 0.018 | Acc: 99.473% \n",
      "[epoch:14, iter:1413] Loss: 0.018 | Acc: 99.461% \n",
      "[epoch:14, iter:1414] Loss: 0.018 | Acc: 99.467% \n",
      "[epoch:14, iter:1415] Loss: 0.018 | Acc: 99.473% \n",
      "[epoch:14, iter:1416] Loss: 0.018 | Acc: 99.479% \n",
      "[epoch:14, iter:1417] Loss: 0.018 | Acc: 99.485% \n",
      "[epoch:14, iter:1418] Loss: 0.018 | Acc: 99.490% \n",
      "[epoch:14, iter:1419] Loss: 0.017 | Acc: 99.496% \n",
      "[epoch:14, iter:1420] Loss: 0.017 | Acc: 99.501% \n",
      "[epoch:14, iter:1421] Loss: 0.017 | Acc: 99.507% \n",
      "[epoch:14, iter:1422] Loss: 0.017 | Acc: 99.512% \n",
      "[epoch:14, iter:1423] Loss: 0.017 | Acc: 99.501% \n",
      "[epoch:14, iter:1424] Loss: 0.017 | Acc: 99.506% \n",
      "[epoch:14, iter:1425] Loss: 0.017 | Acc: 99.511% \n",
      "[epoch:14, iter:1426] Loss: 0.017 | Acc: 99.516% \n",
      "[epoch:14, iter:1427] Loss: 0.017 | Acc: 99.505% \n",
      "[epoch:14, iter:1428] Loss: 0.017 | Acc: 99.509% \n",
      "Waiting Val...\n",
      "Val's ac is: 0.000%\n",
      "save epoch 13 model\n",
      "\n",
      "Epoch: 15\n",
      "[epoch:15, iter:1429] Loss: 0.009 | Acc: 100.000% \n",
      "[epoch:15, iter:1430] Loss: 0.006 | Acc: 100.000% \n",
      "[epoch:15, iter:1431] Loss: 0.005 | Acc: 100.000% \n",
      "[epoch:15, iter:1432] Loss: 0.007 | Acc: 100.000% \n",
      "[epoch:15, iter:1433] Loss: 0.006 | Acc: 100.000% \n",
      "[epoch:15, iter:1434] Loss: 0.006 | Acc: 100.000% \n",
      "[epoch:15, iter:1435] Loss: 0.005 | Acc: 100.000% \n",
      "[epoch:15, iter:1436] Loss: 0.011 | Acc: 99.609% \n",
      "[epoch:15, iter:1437] Loss: 0.012 | Acc: 99.479% \n",
      "[epoch:15, iter:1438] Loss: 0.011 | Acc: 99.531% \n",
      "[epoch:15, iter:1439] Loss: 0.015 | Acc: 99.290% \n",
      "[epoch:15, iter:1440] Loss: 0.015 | Acc: 99.349% \n",
      "[epoch:15, iter:1441] Loss: 0.014 | Acc: 99.399% \n",
      "[epoch:15, iter:1442] Loss: 0.014 | Acc: 99.330% \n",
      "[epoch:15, iter:1443] Loss: 0.013 | Acc: 99.375% \n",
      "[epoch:15, iter:1444] Loss: 0.014 | Acc: 99.316% \n",
      "[epoch:15, iter:1445] Loss: 0.014 | Acc: 99.357% \n",
      "[epoch:15, iter:1446] Loss: 0.013 | Acc: 99.392% \n",
      "[epoch:15, iter:1447] Loss: 0.013 | Acc: 99.342% \n",
      "[epoch:15, iter:1448] Loss: 0.013 | Acc: 99.375% \n",
      "[epoch:15, iter:1449] Loss: 0.013 | Acc: 99.405% \n",
      "[epoch:15, iter:1450] Loss: 0.014 | Acc: 99.361% \n",
      "[epoch:15, iter:1451] Loss: 0.020 | Acc: 99.321% \n",
      "[epoch:15, iter:1452] Loss: 0.020 | Acc: 99.349% \n",
      "[epoch:15, iter:1453] Loss: 0.024 | Acc: 99.312% \n",
      "[epoch:15, iter:1454] Loss: 0.024 | Acc: 99.279% \n",
      "[epoch:15, iter:1455] Loss: 0.024 | Acc: 99.306% \n",
      "[epoch:15, iter:1456] Loss: 0.023 | Acc: 99.330% \n",
      "[epoch:15, iter:1457] Loss: 0.023 | Acc: 99.353% \n",
      "[epoch:15, iter:1458] Loss: 0.022 | Acc: 99.375% \n",
      "[epoch:15, iter:1459] Loss: 0.021 | Acc: 99.395% \n",
      "[epoch:15, iter:1460] Loss: 0.021 | Acc: 99.365% \n",
      "[epoch:15, iter:1461] Loss: 0.022 | Acc: 99.290% \n",
      "[epoch:15, iter:1462] Loss: 0.022 | Acc: 99.311% \n",
      "[epoch:15, iter:1463] Loss: 0.021 | Acc: 99.330% \n",
      "[epoch:15, iter:1464] Loss: 0.021 | Acc: 99.349% \n",
      "[epoch:15, iter:1465] Loss: 0.021 | Acc: 99.367% \n",
      "[epoch:15, iter:1466] Loss: 0.020 | Acc: 99.383% \n",
      "[epoch:15, iter:1467] Loss: 0.020 | Acc: 99.399% \n",
      "[epoch:15, iter:1468] Loss: 0.020 | Acc: 99.375% \n",
      "[epoch:15, iter:1469] Loss: 0.020 | Acc: 99.352% \n",
      "[epoch:15, iter:1470] Loss: 0.020 | Acc: 99.368% \n",
      "[epoch:15, iter:1471] Loss: 0.020 | Acc: 99.382% \n",
      "[epoch:15, iter:1472] Loss: 0.019 | Acc: 99.396% \n",
      "[epoch:15, iter:1473] Loss: 0.019 | Acc: 99.410% \n",
      "[epoch:15, iter:1474] Loss: 0.019 | Acc: 99.389% \n",
      "[epoch:15, iter:1475] Loss: 0.019 | Acc: 99.402% \n",
      "[epoch:15, iter:1476] Loss: 0.018 | Acc: 99.414% \n",
      "[epoch:15, iter:1477] Loss: 0.018 | Acc: 99.426% \n",
      "[epoch:15, iter:1478] Loss: 0.019 | Acc: 99.438% \n",
      "[epoch:15, iter:1479] Loss: 0.018 | Acc: 99.449% \n",
      "[epoch:15, iter:1480] Loss: 0.019 | Acc: 99.429% \n",
      "[epoch:15, iter:1481] Loss: 0.019 | Acc: 99.440% \n",
      "[epoch:15, iter:1482] Loss: 0.019 | Acc: 99.421% \n",
      "[epoch:15, iter:1483] Loss: 0.019 | Acc: 99.432% \n",
      "[epoch:15, iter:1484] Loss: 0.019 | Acc: 99.442% \n",
      "[epoch:15, iter:1485] Loss: 0.018 | Acc: 99.452% \n",
      "[epoch:15, iter:1486] Loss: 0.018 | Acc: 99.461% \n",
      "[epoch:15, iter:1487] Loss: 0.018 | Acc: 99.470% \n",
      "[epoch:15, iter:1488] Loss: 0.018 | Acc: 99.453% \n",
      "[epoch:15, iter:1489] Loss: 0.018 | Acc: 99.462% \n",
      "[epoch:15, iter:1490] Loss: 0.017 | Acc: 99.471% \n",
      "[epoch:15, iter:1491] Loss: 0.017 | Acc: 99.479% \n",
      "[epoch:15, iter:1492] Loss: 0.017 | Acc: 99.487% \n",
      "[epoch:15, iter:1493] Loss: 0.017 | Acc: 99.495% \n",
      "[epoch:15, iter:1494] Loss: 0.017 | Acc: 99.503% \n",
      "[epoch:15, iter:1495] Loss: 0.018 | Acc: 99.487% \n",
      "[epoch:15, iter:1496] Loss: 0.018 | Acc: 99.494% \n",
      "[epoch:15, iter:1497] Loss: 0.018 | Acc: 99.479% \n",
      "[epoch:15, iter:1498] Loss: 0.018 | Acc: 99.487% \n",
      "[epoch:15, iter:1499] Loss: 0.017 | Acc: 99.494% \n",
      "[epoch:15, iter:1500] Loss: 0.017 | Acc: 99.501% \n",
      "[epoch:15, iter:1501] Loss: 0.017 | Acc: 99.508% \n",
      "[epoch:15, iter:1502] Loss: 0.017 | Acc: 99.514% \n",
      "[epoch:15, iter:1503] Loss: 0.017 | Acc: 99.521% \n",
      "[epoch:15, iter:1504] Loss: 0.017 | Acc: 99.527% \n",
      "[epoch:15, iter:1505] Loss: 0.017 | Acc: 99.513% \n",
      "[epoch:15, iter:1506] Loss: 0.017 | Acc: 99.519% \n",
      "[epoch:15, iter:1507] Loss: 0.017 | Acc: 99.506% \n",
      "[epoch:15, iter:1508] Loss: 0.017 | Acc: 99.492% \n",
      "[epoch:15, iter:1509] Loss: 0.017 | Acc: 99.498% \n",
      "[epoch:15, iter:1510] Loss: 0.017 | Acc: 99.505% \n",
      "[epoch:15, iter:1511] Loss: 0.016 | Acc: 99.511% \n",
      "[epoch:15, iter:1512] Loss: 0.016 | Acc: 99.516% \n",
      "[epoch:15, iter:1513] Loss: 0.016 | Acc: 99.522% \n",
      "[epoch:15, iter:1514] Loss: 0.016 | Acc: 99.528% \n",
      "[epoch:15, iter:1515] Loss: 0.016 | Acc: 99.533% \n",
      "[epoch:15, iter:1516] Loss: 0.016 | Acc: 99.538% \n",
      "[epoch:15, iter:1517] Loss: 0.016 | Acc: 99.544% \n",
      "[epoch:15, iter:1518] Loss: 0.016 | Acc: 99.549% \n",
      "[epoch:15, iter:1519] Loss: 0.015 | Acc: 99.554% \n",
      "[epoch:15, iter:1520] Loss: 0.015 | Acc: 99.558% \n",
      "[epoch:15, iter:1521] Loss: 0.015 | Acc: 99.563% \n",
      "[epoch:15, iter:1522] Loss: 0.015 | Acc: 99.568% \n",
      "[epoch:15, iter:1523] Loss: 0.015 | Acc: 99.572% \n",
      "[epoch:15, iter:1524] Loss: 0.015 | Acc: 99.561% \n",
      "[epoch:15, iter:1525] Loss: 0.015 | Acc: 99.565% \n",
      "[epoch:15, iter:1526] Loss: 0.015 | Acc: 99.570% \n",
      "[epoch:15, iter:1527] Loss: 0.015 | Acc: 99.574% \n",
      "[epoch:15, iter:1528] Loss: 0.015 | Acc: 99.578% \n",
      "[epoch:15, iter:1529] Loss: 0.015 | Acc: 99.582% \n",
      "[epoch:15, iter:1530] Loss: 0.015 | Acc: 99.586% \n",
      "Waiting Val...\n",
      "Val's ac is: 0.000%\n",
      "save epoch 14 model\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import os\n",
    "import torchvision.models as models\n",
    " \n",
    " \n",
    "def main():\n",
    "    \n",
    "    # 2. load model\n",
    "    num_class = 11\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    fc_inputs = model.fc.in_features\n",
    "    model.fc = nn.Linear(fc_inputs, num_class)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # 3. prepare super parameters\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    learning_rate = 0.0001\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    epoch = 15\n",
    " \n",
    "    # 4. train\n",
    "    val_acc_list = []\n",
    "    for epoch in range(0, epoch):\n",
    "        print('\\nEpoch: %d' % (epoch + 1))\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        correct = 0.0\n",
    "        total = 0.0\n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            length = len(train_loader)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images) # torch.size([batch_size, num_class])\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            sum_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels.data).cpu().sum()\n",
    "            print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% ' \n",
    "                % (epoch + 1, (batch_idx + 1 + epoch * length), sum_loss / (batch_idx + 1), 100. * correct / total))\n",
    "            \n",
    "        #get the ac with testdataset in each epoch\n",
    "        print('Waiting Val...')\n",
    "        with torch.no_grad():\n",
    "            correct = 0.0\n",
    "            total = 0.0\n",
    "            for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "                model.eval()\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, dim=1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "            print('Val\\'s ac is: %.3f%%' % (100 * correct / total))\n",
    "            \n",
    "            acc_val = 100 * correct / total\n",
    "            val_acc_list.append(acc_val)\n",
    " \n",
    " \n",
    "        torch.save(model.state_dict(), \"/home/yuchi/AI/M1354024_best.ckpt\")\n",
    "        if acc_val == max(val_acc_list):\n",
    "            torch.save(model.state_dict(), \"/home/yuchi/AI/M1354024_best.ckpt\")\n",
    "            print(\"save epoch {} model\".format(epoch))\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "model_best = models.resnet50(pretrained=True)\n",
    "fc_inputs = model_best.fc.in_features\n",
    "model_best.fc = nn.Linear(fc_inputs, 11)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model_best.to(device)\n",
    "model_best.load_state_dict(torch.load(f\"/home/yuchi/AI/M1354024_best.ckpt\"))\n",
    "model_best.eval()\n",
    "prediction = []\n",
    "with torch.no_grad():\n",
    "    for data,_ in test_loader:\n",
    "        test_pred = model_best(data.to(device))\n",
    "        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
    "        prediction += test_label.squeeze().tolist()\n",
    "#create test csv\n",
    "def pad4(i):\n",
    "    return \"0\"*(4-len(str(i)))+str(i)\n",
    "df = pd.DataFrame()\n",
    "df[\"Id\"] = [pad4(i) for i in range(1,len(test_dataset)+1)]\n",
    "df[\"Category\"] = prediction\n",
    "df.to_csv(\"/home/yuchi/AI/submission.csv\",index = False)\n",
    "print(\"done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch230",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
